# 1. Linear Regression

지도학습: 회귀 + 분류

- 머신러닝이란 데이터로부터 유용한 예측을 하기 위해 모델이라고 불리는 소프트웨어를 학습시키는 과정

- 머신러닝 모델이란 예측에 활용할 수 있는 데이터 간의 수학적 관계, 규칙, 패턴 등을 의미
- 머신러닝의 목적은 기존의 데이터로부터 패턴을 학습한 뒤 새로운 데이터가 들어왔을 때 예측을 잘 하는 것

머신러닝의 종류

1. 지도학습
   - 컴퓨터는 답이 있는 데이터를 학습하며 데이터와 답 간의 규칙을 파악함

2. 비지도학습
   - 컴퓨터는 답이 없는 데이터를 학습하며 데이터 내의 의미있는 패턴을 찾아냄

3. 강화학습
   - 특정 환경 내에서 컴퓨터의 액션에 보상 혹은 페널티를 주며 예측을 함. 가장 많은 보상을 얻을 수 있는 전략을 찾아내는 방법


> 지도학습은 컴퓨터가 답이 있는 데이터를 학습하며 데이터와 답 간의 규칙을 파악함

### 데이터

- 데이터셋은 각 샘플의 특성과 라벨로 이루어져 있어야 함

### 모델

- 모델이란 데이터의 입력 특성들과 타겟 간의 수학적 관계를 정의 한 것
- 모델은 학습을 통해 패턴을 찾아냄

### 평가
- 모델이 학습을 잘 했는지 확인하기 위해 학습된 모델을 평가해야 함
- 모델의 예측값과 실제값을 비교하여 모델을 평가하고 이 결과에 따라 학습과 검증의 과정이 더 필요할지 혹은 모델을 배포할지 결정

### 추론
- 만족스로운 성능의 모델이 만들어졌으면 새로운 데이터에 대해 예측을 수행


## 지도학습의 종류

### 회귀
- 연속적인 값을 예측하는 문제

### 분류
- 데이터의 특정 범주에 속할 확률을 예측하는 문제
- 이진 분류 / 다중 분류


### 기준모델
- 예측 모델을 만들기 앞서 가장 간단하면서도 직관적이며 최소한의 성능을 나타내는 베이스라인 모델이 필요함
- 성능 하한선의 기준
- 회귀문제는 타겟의 평균값
- 분류문제는 최빈 클래스
- 시계열문제는 이전 타임스탬프 값

## 선형회귀모델
잔차: 실제값 - 모델의 예측값

잔차를 최소로 하는 선을 구하는 것

오차: 모집단에서의 예측값과 실제값의 차이

최적의 선형회귀선은 잔차 제곱들의 합인 RSS를 최소로 하는 직선(잔차제곱합 최소)

RSS는 선형회귀모델의 비용함수임

모델을 학습한다는 것은 이 비용함수를 최소로 하는 파라미터를 찾는 것

### 최소제곱법 OLS
잔차제곱합을 최소로 만들어 주는 방법을 최소제곱법(OLS)이라고 함


새로운 데이터를 예측하는 방법
1. 보간(interpolate): 모델이 학습한 데이터 구간 안에 있는 값을 예측하는 방법
2. 외삽(extrapolate): 모델이 학습한 데이터 구간 바깥에 있는 값을 예측하는 방법

### 단순선형회귀
- 하나의 독립변수로 종속변수를 설명하는 선형회귀

### 다중선형회귀
- 두 개 이상의 독립변수로 종속변수를 설명하는 선형회귀

### 다항선형회귀
- 2차항 이상의 독립변수로 종속변수를 설명하는 선형회귀
- 다차항도 하나의 feature가 되기 때문에 선형 괸계로 표현할 수 있음

## 회귀 평가지표

- MSE
  - 제곱오차의 평균
  - 미분가능하여 비용함수로 가장 흔하게 사용
  - 제곱을 취하기 때문에 이상치에 민감

- RMSE
  - MSE에 루트를 씌웠기 때문에 상대적으로 덜 민감
  - 값의 크기가 실제값과 비슷해지기 때문에 직관적으로 이해하기 쉬움

- MAE
  - 절대오차의 평균
  - 오차의 절대값이기 때문에 이상치에 민감하지 않음

- R_2
  - 결정계수는 모델의 설명력을 나타냄
  - 1에 가까울수록 설명력이 높고 0에 가까울수록 낮음

SSE: 관측치와 예측치의 차이

SSR: 예측치와 평균의 차이

SST: 관측치와 평균의 차이

## 선형회귀모델의 계수(Coefficients)

- 상수항은 의미가 없고 해석하지 않는다
- 상수항을 포함해야 하는 이유는 평균이 0인 잔차를 가지기 때문
- 안넣으면 X 와 Y는 0으로 같아지려는 문제가 있기 때문에 편의가 크게 발생함


# 2. Gerneralization (일반화)

일반화란 모델을 만드는 데 사용된 분포와 동일한 분포에서 추출한 이전에는 볼 수 없었던 새로운 데이터에 적절하게 적응하는 모형의 능력을 의미

머신러닝의 목적은 일반화가 잘 된 예측 모델을 만드는 것이라 할 수 있음

## Data Split & Validation

### Hold out

데이터 세트를 두 가지로 분할해서 사용

- training data: 모델을 학습시키기 위한 세트
- test data: 모델을 테스트하기 위한 세트

테스트 데이터는 데이터 사이즈가 충분히 커야 하고, 훈련 데이터와 다른 특징을 가진 데이터여서는 안 된다

### 3-way hold out

1. training data
2. validation data
3. test data
   
가장 마지막에 단 한 번 테스트 세트를 이용해 결과를 확인해야 함

## Cross-validation

3-way hold out 방법의 문제

1. 데이터의 크기가 작을 경우 적절하지 않음
2. 모델 선택의 문제
   - 어떤 알고리즘을 사용할 것인가
   - 어떤 하이퍼파라미터를 사용할 것인가
   - 홀드아웃 검증은 학습의 결과가 무작위로 선택된 다음 학습 및 검증 세트에 의해 달라질 수 있음. 이는 모델의 신뢰성에 의문을 제기

교차검증은 훈련 세트의 모든 샘플이 검증에 사용됨

k-fold cross-validation 방법이 많이 사용

k-fold cross-validation은 데이터를 모두 사용해 k번 학습과 검증을 반복함

1. 데이터를 k 개로 분할
2. 1개 부분은 검증세트로 사용하고 나머지 k-1 개 부분은 모두 훈련에 사용
3. k번 검증 결과를 종합해 전체 모델의 성능을 평가

## 과적합 & 과소적합

일반화 오차가 큰 모델은 학습이 잘 이루어지지 않은 것

1. 과적합
   - 과적합은 훈련 데이터셋의 디테일과 노이즈까지 모두 학습하여 새로운 데이터를 잘 예측하지 못하는 현상
   - 훈련 데이터셋에서의 성능은 높지만 테스트 데이터셋에서의 성능은 낮음
   - 유연성이 높은 비선형 모델에서 나타날 가능성이 높음

2. 과소적합
   - 훈련 데이터셋도 제대로 학습하지 못해 새로운 데이터를 잘 예측하지 못하는 현상

## 분산 & 편향

과적합과 과소적합은 편향과 분산과 관계가 있음

### 편향 (Bias)

- 편향은 모델의 예측값과 실제 값과의 차이를 의미
- 편향은 잘못된 알고리즘 가정에서 오는 에러. 즉 모델의 가정에서 오는 에러
- 편향이 큰 모델은 특성과 타겟 간의 관계를 제대로 파악하지 못하기 때문에 과소적합이 일어날 수 있음


### 분산 (Vairance)

- 분산은 서로 다른 데이터가 들어왔을 경우 모델의 예측값이 변동되는 양을 의미
- 분산 에러는 훈련 데이터세트의 결과에서 작은 변동이 있을 경우 모델이 얼마나 민감하게 반응하는지에 따른 에러임
- 분산이 큰 모델은 훈련 데이터의 노이즈까지 학습하여 과적합이 일어날 수 있음

### 분산과 편향의 Trade-off

MSE = 감소가능 에러 + 감소불가능 에러 로 표현하면

감소가능 에러 = Bias 에러 + Variance 에러 로 나눠짐

MSE가 고정되어 있다는 가정 하에 분산 에러가 커지면 편향 에러는 작아지고,

반대로 편향 에러가 커지면 분산 에러는 작아짐

- 모델의 복잡도를 변경하며 중간의 일반화가 잘 되는 지점을 찾아야 함
- 모델이 복잡해질수록 분산 에러가 커지고 모델이 단순해질수록 편향 에러가 커짐
- 모델의 복잡도는 데이터의 크기에 따라 달라질 수 있음

나에게 주어진 데이터셋을 완전히 믿을 수 없기 때문에 나타나는 문제

- 편향을 줄이는 행위는, 내가 지금 가지고 있는 데이터세트가 현실의 전체 데이터를 잘 대표하고 있을 것이라고 강하게 믿을 때
- 내가 가지고 있는 데이터세트의 크기가 커질수록 세상을 더 잘 반영할 때 편향을 줄임

- 분산을 줄이는 행위는, 내가 지금 가지고 있는 데이터세트를 완벽하게 못 믿을 때
- 내가 가지고 있는 데이터세트의 크기가 작으면, 세상을 대표할 가능성이 작으므로 모델을 단순하게 해서 분산을 줄여야 함

# 3. Regularized Regression

정규화 회귀모델

릿지, 라쏘

## 과적합 방지 방법

1. 더 많은 데이터를 학습시키기 & 교차검증
2. 특성을 잘 선택해서 훈련하기
3. 정규화 모델
   1. 모델에 규제항을 더해 기존 모델보다 단순하게 만들기
   2. 규제항은 회귀계수의 값이 너무 커지는 것을 방지하여 과적합을 예방할 수 있음


## 정규화 회귀모델

- 선형모델에 규제항을 더해 과적합을 방지하는 방법
- 규제항은 회귀계수를 감소시켜 예측에 미치는 영향력을 축소시킴 -> 일반화
- 모델에 편향을 조금 더하고 분산을 줄이는 것


### Ridge Regression

- 회귀계수에 가중치들의 제곱합(L2 penalty)을 페널티로 부과하여 회귀계수의 크기를 줄임
- L2 페널티를 적용하면 영향력이 크지 않은 회귀계수의 값은 0에 가깝게 축소
- L2 페널티는 회귀계수의 제곱이기 때문에 회귀계수가 움직일 수 있는 공간이 원형 형태

### Lasso Regression
- 회귀계수에 가중치들의 절대값들의 합(L1 penalty)을 페널티로 부과하여 회귀계수의 크기를 줄임
- 영향력이 크지 않은 회귀계수의 값을 0으로 만듬
- 자동으로 특성을 선택하는 효과를 가지게 되며 희소모델(sparse model)을 만듬
- 회소모델이란 가중치가 0인 특성이 많은 모델을 의미
- L1 페널티는 회귀계수의 절대값이기 때문에 회귀계수가 움직일 수 있는 공간이 마름모 꼴 형태

### $\lambda$
- 람다는 페널티의 강도를 조절하는 하이퍼파라미터
- 람다의 크기가 클수록 회귀계수의 값이 줄어듬
- $\lambda = 0$ 이면 기존의 선형회귀와 같음
- $\lambda = \infty$ 이면 회귀계수 $\beta = 0$ 이 됨

## Preprocessing

### Scaling

- 정규화 모델은 특성의 스케일을 표준화하는 것이 필요
- StandardScaler

### Encoding

- 문자열 범주형 변수를 수치형으로 변환해줘야 함
- 순서가 없는 범주형, 명목형 변수는 One-Hot Encoding을 사용
- 범주가 너무 많은 경우(high cardinality)에는 원핫인코딩 부적절

## Feature Selection

### Sklearn SelectKBest
- ANOVA F-value between label/feature for classification tasks
- 종속변수와 독립변수의 ANOVA F-value를 기준으로 선택이 기본 설정

### Sklearn RidgeCV, LassoCV

교차검증 알고리즘 제공함

# 4. Logistic Regression

## 분류(Classification)

1. 타겟
   - 분류 문제는 데이터가 속할 특정 범주(특정 범주에 속할 확률)을 예측
   - 이진 분류
   - 다중 분류

2. 기준모델
   - 보통 최빈 클래스 값을 기준모델로 설정
   - 분류 문제는 타겟 변수가 편중된 범주 비율을 가지고 있는 경우가 많음

3. 평가지표
   - 분류 문제의 평가지표로는 다음과 같은 것들이 있음
     - Accuracy (정확도)
     - Recall (재현율)
     - Precision (정밀도)
     - F1 score
     - roc_auc_score

선형회귀로는 분류 문제를 풀 수 없다. 결과값이 무한대에 걸치기 때문

선형회귀에 시그모이드 함수를 씌우면 확률을 구할 수 있음

$$
\sigma \left( x\right) =\dfrac{1}{1+e^{-x}}
$$

## 로지스틱 회귀

- 로지스틱 회귀모델은 0과 1 사이의 값을 출력하며 출력값이 0.5 이상일 경우는 Class 1,

- 0.5 미만일 경우는 Class 0 으로 분류

- 오즈(odds): 실패에 대한 성공의 비율, 사전이 발생할 확률을 사건이 발생하지 않을 확률로 나눈 비율 ($\frac{p}{1-p}$)

- 로짓: 무한대의 범위에서 어떤 클래스에 속할 확률을 결정하는 함수, 오즈의 무한대로 발산하는 범위 제약을 극복하기 위해 로그함수를 취함
  
- 로그 오즈: 변환 모델의 종속변수, 이 값을 통해 확률을 구함
  
- 정확도(Accuracy) = 맞게 예측한 수 / 전체 예측 수

- sklearn의 로지스틱 회귀모델은 디폴트로 L2 penalty 가 적용되는 모델
- 따라서 데이터 스케일링을 통해 표준화를 해줘야 함

로지스틱 회귀모델의 계수 해석
- 회귀계수가 양수인 경우 1일 확률이 높아지고 회귀계수가 음수인 경우 1일 확률이 낮아짐
- 회귀계수의 절대값이 클 수록 영향력이 큼
- 로지스틱 회귀분석에서 회귀계수는 해당 변수가 1 증가함에 따른 로그 승산(odds)의 변화량을 의미
- **$x_i$가** 1만큼 증가할 때, **해당 입력 데이터가 1로 분류될 확률의 $logit(p)$이** $\beta_i$만큼 증가한다
- 즉, **$x_i$가** 1만큼 증가할 때, **$odds(p)$이** $e^{\beta_i}$배가 되는 것

### Odds Ratio

로지스틱 회귀분석에서 나머지 변수는 모두 고정시킨 상태에서 한 변수를 1만큼 증가시켰을 때 변화하는 오즈의 비율

x1이 1 만큼 증가한다면, 성공에 대한 오즈비가

$e^{\widehat{\beta }_{1}}$

만큼 변화함

## Confusion Matrix(혼동행렬)

분류기가 예측한 결과와 실제 결과에 대한 레코드의 개수를 표시한 테이블

- TP: 실제 참인 것을 참이라고 정확하게 예측한 경우
- FP: 실제 거짓인 것을 참이라고 잘못 예측한 경우
- FN: 실제 참인 것을 거짓이라고 잘못 예측한 경우
- TN: 실제 거짓인 것을 거짓이라고 정확하게 예측한 경우

- 정확도(Accuracy): 전체 범주를 모두 바르게 맞춘 경우를 전체 수로 나눈 값: TP + TN / Total
- 정밀도(Precision): 참으로 예측한 경우 올바르게 참을 맞춘 비율: TP / TP + FP
- 재현율(Recall): 실제 참인 것 중 올바르게 참을 맞춘 것의 비율: TP / TP + FN
- F1 score: 정밀도와 재현율의 조화평균: $2\cdot \dfrac{precision\cdot recall}{precision+recall}$

중요한 문제의 경우, FN 오류가 FP 오류보다 치명적임

따라서 재현율을 높이는 것이 중요함

## ROC, AUC (Receiver Operating Characteristic, Area Under the Curve)
- 모델이 예측하는 확률, 모델의 예측값 자체를 평가하는 지표

### ROC curve
- roc curve는 여러 임계값에 대해 TPR(True Positive Rate, recall)과 FPR(False Positive Rate)을 그래프로 보여줌
  
- **Recall(재현율) = Sensitivity(민감도)** = ${\displaystyle \mathrm {TPR} ={\frac {\mathrm {TP} }{\mathrm {P} }}={\frac {\mathrm {TP} }{\mathrm {TP} +\mathrm {FN} }}=1-\mathrm {FNR} }$

**Fall-out(위양성률)** = ${\displaystyle \mathrm {FPR} ={\frac {\mathrm {FP} }{\mathrm {N} }}={\frac {\mathrm {FP} }{\mathrm {FP} +\mathrm {TN} }}=1-\mathrm {TNR(Specificity)} }$

- 재현율을 높이기 위해서는 Positive로 판단하는 임계값을 계속 낮추어 모두 Positive로 판단하게 만들면 됨. 대신 이러면 위양성률도 높아짐

### AUC

- ROC 곡선 아래의 면적을 이용해 분류 모델의 성능을 나타내는 지표로 구한 것
- 일반적으로 AUC 값이 1에 가까울수록 성능이 좋고 0.5에 가까울수록 성능이 안 좋음
- 머신러닝 이진 분류 모델의 예측 성능 판단에 중요하게 사용되는 평가지표
- 분류 결과보다 모델의 예측 확률값 자체가 중요한 경우에 많이 사용됨(영화추천모델)
- AUC score는 모델이 Positive 샘플의 예측값을 Negative 샘플의 예측값보다 크게 줄 확률
- AUC 가 0.8 이면, Positive 샘플의 확률이 Negative 샘플의 확률보다 클 확률이 0.8 이라는 의미
- TPR(최대) - FPR(최소) 이 최대가 되는 지점이 최적의 임계값