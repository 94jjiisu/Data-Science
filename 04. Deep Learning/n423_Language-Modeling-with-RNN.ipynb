{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPvOR0k4UHW3nXidsL2nIm5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 언어 모델과 RNN(Recurrent Neural Network, 순환 신경망)\n","\n","\n","## 학습 목표\n","\n","- 언어 모델 (Language Model)\n","    - 통계 기반 언어모델을 이해하고 설명할 수 있습니다.\n","    - 통계 기반 언어모델의 한계를 이해하고 이를 극복하기 위해 등장한 신경망 언어 모델의 장점을 설명할 수 있습니다. \n","\n","- 순환 신경망 (Recurrent Neural Network, RNN)\n","    - RNN의 구조와 작동 방식을 이해하고 설명할 수 있습니다.\n","    - RNN의 장점과 단점을 설명하고 이해할 수 있습니다.\n","\n","- LSTM & GRU\n","    - LSTM과 GRU가 고안된 배경과 구조를 연관지어 설명할 수 있습니다.\n","    - 두 방법의 차이에 대해서 설명할 수 있습니다.\n","\n","- Attention\n","    - Attention이 탄생하게 된 배경에 대해서 설명할 수 있습니다.\n","    - Attention의 장점에 대해서 설명하고 Attention 으로도 해결할 수 없는 RNN의 구조적 단점에 대해서도 이해할 수 있습니다.\n","\n","\n","- [RNN 소개 영상](https://youtu.be/PahF2hZM6cs)\n","\n","- [LSTM 소개 영상](https://youtu.be/bX6GLbpw-A4)\n","\n","- [Seq2Seq 구조와 Attention 소개 영상](https://youtu.be/WsQLdu2JMgI)\n"],"metadata":{"id":"EGfYl-d0QJVJ"}},{"cell_type":"markdown","source":["## 1. 언어 모델 (Language Model)"],"metadata":{"id":"_nqxD2kDQPvh"}},{"cell_type":"markdown","source":["언어 모델이란 문장과 같은 단어 시퀀스에서 각 단어의 확률을 계산하는 모델입니다.<br/>\n","이전 시간에 배운 **`Word2Vec`** 역시 여러 가지 언어 모델 중 하나입니다.<br/>\n","**`CBoW`** 에서는 주변 단어의 정보를 바탕으로 타겟 단어의 확률을 할당했습니다.\n","\n","익숙하지 않을 수 있겠지만 수식으로 먼저 생각해보겠습니다.<br/>\n","$l$개의 단어로 구성된 문장은 아래와 같이 나타낼 수 있겠습니다.\n","\n","> $w_1, w_2, w_3, ..., w_l$\n","\n","`CBoW`가 타겟 단어(target word)를 예측할 확률 $P(w_t)$ 은 아래와 같이 구해집니다.\n","\n","> $P(w_t \\vert w_{t-2},w_{t-1},w_{t+1},w_{t+2})$"],"metadata":{"id":"WFqaw-okQQRo"}},{"cell_type":"markdown","source":["`Word2Vec` 이 나오기 전까지 많은 언어 모델은 목표 단어 왼쪽의 단어만을 고려하여 확률을 계산하였습니다.<br/>\n","$t$ 번째로 단어를 예측하기 위해서 0번째 부터 $t-1$ 번째 까지의 모든 단어 정보를 사용합니다.\n","\n","언어 모델이 목표 단어 왼쪽의 단어만을 고려할 때 문장에서 $t$ 번째에 해당하는 단어를 예측할 확률은 아래와 같이 나타낼 수 있습니다.\n","\n","> $P(w_t \\vert w_{t-1},w_{t-2}, \\cdots ,w_1,w_0)$\n","\n","$l$ 개의 단어로 이루어진 문장이 만들어질 확률은 아래 식과 같아집니다.\n","\n","> $P(w_0,w_1, \\cdots, w_{l-1}, w_l) = P(w_0)P(w_1 \\vert w_0) \\cdots P(w_{l-1} \\vert w_{l-2}, \\cdots, w_1, w_0)P(w_l \\vert w_{l-1}, w_{l-2}, \\cdots, w_1, w_0)$"],"metadata":{"id":"6zxSbT9hQSmb"}},{"cell_type":"markdown","source":["수식이 익숙하지 않을 수 있으니 예시로 한 번 더 살펴보겠습니다.\n","\n","위 언어 모델을 사용하여 \"I am a student\" 라는 문장이 만들어질 확률을 구하면 아래와 같습니다.\n","\n","> $P(\\text{\"I\",\"am\",\"a\",\"student\"}) = P(\\text{\"I\"}) \\times P(\\text{\"am\"} \\vert \\text{\"I\"}) \\times P(\\text{\"a\"} \\vert \\text{\"I\",\"am\"}) \\times P(\\text{\"student\"} \\vert \\text{\"I\",\"am\",\"a\"})$\n","\n","앞 단어 들이 등장했을 때 특정 단어가 등장할 확률을 조건부 확률로 구하게 됩니다.<br/>"],"metadata":{"id":"Ndyn2ngLQThz"}},{"cell_type":"markdown","source":["### 2) 통계적 언어 모델 (Statistical Language Model, SLM)\n","\n","통계적 언어 모델은 신경망 언어 모델이 주목받기 전부터 연구되어 온 전통적인 접근 방식입니다.\n","\n","\n","- **통계적 언어 모델의 확률 계산**\n","\n","통계적 언어 모델에서는 단어의 등장 횟수를 바탕으로 조건부 확률을 계산합니다.\n","\n","다시 _\"I am a student\"_ 라는 문장을 만드는 예시를 생각해보겠습니다.\n","\n","> $P(\\text{\"I\",\"am\",\"a\",\"student\"}) = P(\\text{\"I\"}) \\times P(\\text{\"am\"} \\vert \\text{\"I\"}) \\times P(\\text{\"a\"} \\vert \\text{\"I\",\"am\"}) \\times P(\\text{\"student\"} \\vert \\text{\"I\",\"am\",\"a\"})$\n","\n","첫 번째 항인 $P(\\text{\"I\"})$ 를 구해봅시다. <br/> 전체 말뭉치의 문장 중에서 시작할 때 _\"I\"_ 로 시작하는 문장의 횟수를 구합니다. 전체 말뭉치의 문장이 1000개이고, 그 중 _\"I\"_ 로 시작하는 문장이 100개라면\n","\n","> $$P(\\text{\"I\"}) = \\frac{100}{1000} = \\frac{1}{10}$$\n","\n","다음으로, _\"I\"_ 로 시작하는 100개의 문장 중 바로 다음에 _\"am\"_ 이 등장하는 문장이 50개라면 \n","\n","> $$P(\\text{\"am\"} \\vert \\text{\"I\"}) = \\frac{50}{100} = \\frac{1}{2}$$\n","\n","이런 방식으로 모든 조건부 확률을 구한 뒤 서로를 곱해주면 문장이 등장할 확률 $P(\\text{\"I\",\"am\",\"a\",\"student\"})$ 을 구할 수 있습니다."],"metadata":{"id":"4Wr6Nz93QIeh"}},{"cell_type":"markdown","source":["- **통계적 언어 모델의 한계점**\n","\n","통계적 언어 모델은 횟수 기반으로 확률을 계산하기 때문에 희소성(Sparsity) 문제를 가지고 있습니다. 예를 들어, 학습시킬 말뭉치에 _\"1 times\", \"2 times\", ..._ 라는 표현은 등장하지만 _\"7 times\"_ 라는 표현은 없다고 해보겠습니다.\n","\n","그렇다면 이 말뭉치를 학습한 통계적 언어 모델은 아래와 같은 문장을 절대 만들어 낼 수 없게 됩니다.\n","\n","> \"I studied this section 7 times\"\n","\n","_\"7\"_ 이라는 단어가 등장한 순간 바로 다음 _\"times\"_ 가 등장할 확률은 0이 되어버리기 때문입니다.<br/>\n","이렇게 실제로 사용되는 표현임에도 말뭉치에 등장하지 않았다는 이유로 많은 문장이 등장하지 못하게 되는 문제를 희소 문제라고 합니다.<br/>\n","통계적 언어 모델에서 이런 문제를 개선하기 위해서 N-gram 이나 스무딩(smoothing), 백오프(back-off)와 같은 방법이 고안되었습니다.\n","\n","> ❓ **더 알아보기** <br/>\n","> 1. N-gram : 통계적 언어 모델을 고도화 하기 위한 방법 중 하나인 N-gram에 대해 조사해봅시다.<br/>\n","> 2. Back-off, Smoothing : 희소 문제를 보완하기 위한 장치인 back-off 와 smoothing에 대해 알아봅시다.\n","\n","\n","\n"],"metadata":{"id":"aMe-gkM8QhuU"}},{"cell_type":"markdown","source":["### 3) 신경망 언어 모델 (Neural Langauge Model)\n","\n","신경망 언어 모델에서는 횟수 기반 대신 `Word2Vec`이나 `fastText` 등의 출력값인 임베딩 벡터를 사용합니다. <br/>\n","그렇기 때문에 말뭉치에 등장하지 않더라도 의미적, 문법적으로 유사한 단어라면 선택될 수 있습니다.\n","\n","임베딩 벡터에서는 _\"7\"_ 이라는 단어의 벡터가 _\"1\", \"2\" ..._ 등의 단어와 유사한 곳에 위치합니다. <br/> 그렇기 때문에 말뭉치에 _\"7 times\"_ 라는 표현이 등장하지 않더라도 _\"1 times\", \"2 times\"_ 라는 표현이 등장한다면 언어 모델은\n","\n","> \"I studied this section 7 times\"\n","\n","라는 문장을 만들어 낼 수 있게 됩니다."],"metadata":{"id":"_ASHk3X7Qi1r"}},{"cell_type":"markdown","source":["## 2. 순환 신경망 (RNN, Recurrent Neural Network)\n","\n","인공 신경망 언어 모델에서 사용되는 순환 신경망에 대해 알아보겠습니다.\n","\n","### 연속형 데이터 (Sequential Data)\n","\n","- Sequential Data란?\n","    - 어떤 순서로 오느냐에 따라서 단위의 의미가 달라지는 데이터\n","    - **Non-sequential Data**\n","\n","    <img src=\"https://www.researchgate.net/profile/Kent-Wittenburg/publication/303542822/figure/tbl1/AS:614026883117086@1523406825823/Tabular-data-used-in-examples.png\" width=\"280\"/> <img src=\"https://i.imgur.com/phjsn70.jpg\" width=\"500\"/>\n","\n","    - **Sequential Data**\n","\n","    <img src=\"https://pbs.twimg.com/media/CxJMPgPUsAAcaRQ?format=jpg&name=small\" width=\"400\"/> <img src=\"https://discourse.metabase.com/uploads/default/optimized/2X/1/1391161139879b2a39d3f7f5f013549776769c68_2_690x411.png\" width=\"400\"/>\n","\n","RNN 은 연속형(Sequential) 데이터를 잘 처리하기 위해 고안된 신경망입니다.<br/>\n","RNN의 구조에 대해 알아보도록 하겠습니다.\n"],"metadata":{"id":"pVZc3hN8Qkct"}},{"cell_type":"markdown","source":["### RNN의 구조\n","\n","<img src=\"https://www.easy-tensorflow.com/images/NN/01.png\"/>"],"metadata":{"id":"KgxxxIALQnKr"}},{"cell_type":"markdown","source":["등호 왼쪽을 보면 3개의 화살표가 있습니다.\n","\n","1. 입력 벡터가 은닉층에 들어가는 것을 나타내는 화살표\n","2. 은닉층로부터 출력 벡터가 생성되는 것을 나타내는 화살표\n","3. 은닉층에서 나와 다시 은닉층으로 입력되는 것을 나타내는 화살표.\n","\n","3번 화살표는 기존 신경망에서는 없었던 과정입니다.<br/>\n","이 화살표는 특정 시점에서의 은닉 벡터가 다음 시점의 입력 벡터로 다시 들어가는 과정을 나타내고 있습니다.<br/>\n","출력 벡터가 다시 입력되는 특성 때문에 **'순환(Recurrent) 신경망'** 이라는 이름이 붙었습니다.\n","\n"],"metadata":{"id":"T1iWJFqiQo1k"}},{"cell_type":"markdown","source":["### time-step 별로 펼쳐서 RNN 알아보기\n","\n"],"metadata":{"id":"zJV_npORQqy4"}},{"cell_type":"markdown","source":["기본 네트워크가 왼쪽 그림처럼 표시되지만 신경망을 시점에 따라 펼쳐보면 오른쪽 그림처럼 나타낼 수 있습니다.<br/>\n","$t-1$ 시점에서는 $x_{t-1}$ 와 $h_{t-2}$가 입력되고 $o_{t-1}$ 이 출력됩니다.<br/>\n","$t$ 시점에서는 $x_t$ 와 $h_{t-1}$ 가 입력되고 $o_t$ 이 출력됩니다.<br/>\n","$t+1$ 시점에서는 $x_{t+1}$ 와 $h_t$ 가 입력되고 $o_{t+1}$ 이 출력됩니다.\n","\n","t 시점의 RNN 계층은 그 계층으로의 입력 벡터 $x_t$ 와 1개 전의 RNN 계층의 출력 벡터 $h_{t-1}$ 를 받아들입니다.<br/>\n","입력된 두 벡터를 바탕으로 해당 시점에서의 출력을 아래와 같이 계산합니다. \n","\n","> $h_t = \\tanh(h_{t-1}W_h + x_tW_x + b)$\n","\n","가중치는 $W_h, W_x$ 2개가 있습니다.<br/>\n","각각 입력 x를 h로 변환하기 위한 $W_x$와 RNN의 은닉층의 출력을 다음 h로 변환해주는 $W_h$ 입니다.<br/>\n","b는 각 편향(bias)을 단순화하여 나타낸 항입니다."],"metadata":{"id":"j1zgH07HQrn3"}},{"cell_type":"markdown","source":["이 과정을 그림으로 나타내면 다음과 같습니다.\n"],"metadata":{"id":"OGMnF3iKQuSv"}},{"cell_type":"markdown","source":["<img src=\"https://i.imgur.com/nFMF0Nc.png\" width=\"900\"/>"],"metadata":{"id":"jrDUc6sPQvAh"}},{"cell_type":"markdown","source":["이렇게 하면 t 시점에 생성되는 hidden-state 벡터인 $h_t$ 는 해당 시점까지 입력된 벡터 $x_1, x_2, \\cdots, x_{t-1}, x_t$ 의 정보를 모두 가지고 있습니다.<br/>\n","Sequential 데이터의 순서 정보를 모두 기억하기 때문에 Sequential 데이터를 다룰 때 RNN을 많이 사용합니다."],"metadata":{"id":"X4ozaYPPQvjz"}},{"cell_type":"code","source":["# 배웠던 RNN을 간단한 코드로 살펴보면 다음과 같습니다. \n","import numpy as np\n","\n","class RNN:\n","  def __init__(self, Wx, Wh, b):\n","    self.params = [Wx, Wh, b]\n","    # 필요한 가중치를 초기화하여 줍니다.\n","    self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n","    self.cache = None\n","\n","  def forward(self, x, h_prev):\n","    Wx, Wh, b = self.params\n","    t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b # 이 부분을 위의 그림과 연관지어 생각해보세요!\n","    h_next = np.tanh(t)\n","\n","    self.cache = (x, h_prev, h_next)\n","    return h_next"],"metadata":{"id":"vXa1iliPQgtj","executionInfo":{"status":"ok","timestamp":1679796711735,"user_tz":-540,"elapsed":2,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["### 다양한 형태의 RNN\n","\n","실제로 다양한 형태의 RNN이 있습니다. 아래 그림에서 가장 왼쪽에 위치한 one-to-one은 실질적으로 순환이 적용되지는 않은 형태입니다.<br/>\n","나머지 4개의 RNN이 각각 어떤 분야에 사용되는지 알아보겠습니다."],"metadata":{"id":"amXTFkIrQxzh"}},{"cell_type":"markdown","source":["<img src=\"http://karpathy.github.io/assets/rnn/diags.jpeg\" width=\"900\"/>\n","\n","1. one-to-many : 1개의 벡터를 받아 Sequential한 벡터를 반환합니다. 이미지를 입력받아 이를 설명하는 문장을 만들어내는 **이미지 캡셔닝(Image captioning)**에 사용됩니다.\n","2. many-to-one : Sequential 벡터를 받아 1개의 벡터를 반환합니다. 문장이 긍정인지 부정인지를 판단하는 **감성 분석(Sentiment analysis)**에 사용됩니다.\n","3. many-to-many(1) : Sequential 벡터를 모두 입력받은 뒤 Sequential 벡터를 출력합니다. **시퀀스-투-시퀀스(Sequence-to-Sequence, Seq2Seq) 구조**라고도 부릅니다. 번역할 문장을 입력받아 번역된 문장을 내놓는 **기계 번역(Machine translation)**에 사용됩니다.\n","4. many-to-many(2) : Sequential 벡터를 입력받는 즉시 Sequential 벡터를 출력합니다. **비디오를 프레임별로 분류(Video classification per frame)**하는 곳에 사용됩니다. "],"metadata":{"id":"H7xKv2IpQzNF"}},{"cell_type":"markdown","source":["### RNN의 장점과 단점\n","\n","- **RNN의 장점**\n","\n","RNN은 모델이 간단하고 (이론적으로는) 어떤 길이의 sequential 데이터라도 처리할 수 있다는 장점을 가지고 있습니다.\n","\n","하지만 RNN은 몇 가지 단점을 가지고 있습니다.\n","\n","- RNN의 단점 1 : **병렬화(parallelization) 불가능**\n","\n","RNN 구조가 가지고 있는 단점 중 하나는 벡터가 **순차적으로 입력** 된다는 점입니다.<br/>\n","이는 sequential 데이터 처리를 가능하게 해주는 요인이지만, 이러한 구조는 GPU 연산의 장점인 병렬화를 불가능하게 만듭니다.<br/>\n","그렇기 때문에 RNN 기반의 모델은 GPU 연산을 하였을 때 이점이 거의 없다는 단점을 가지고 있습니다.\n","\n","\n","- RNN의 단점 2: **기울기 폭발(Exploding Gradient), 기울기 소실(Vanishing Gradient)**\n","\n","단순 RNN의 치명적인 문제점은 역전파 과정에서 발생합니다.<br/>\n","역전파 과정에서 RNN의 활성화 함수인 $\\tanh$ 의 미분값을 전달하게 됩니다. \n","$\\tanh$ 를 미분한 함수의 값은 아래와 같습니다."],"metadata":{"id":"-mCjN7QKRyRr"}},{"cell_type":"markdown","source":["<img src=\"https://user-images.githubusercontent.com/45377884/91560164-52a14400-e974-11ea-8bf4-bbfc7fd42deb.png\" width=\"700\"/>\n","\n","\n","위 그래프에서 최댓값이 1이고, (-4,4) 이외의 범위에서는 거의 0에 가까운 값을 나타내는 것을 알 수 있습니다.\n","\n","\n","문제는 역전파 과정에서 이 값을 반복해서 곱해주어야 한다는 점입니다.<br/>\n","이 Recurrent가 10회, 100회 반복된다고 보면, 이 값의 10제곱, 100제곱이 식 내부로 들어가게 됩니다.\n","\n","만약 이 값이 0.9 일 때 10제곱이 된다면 0.349가 됩니다. 이렇게 되면 시퀀스 앞쪽에 있는 hidden-state 벡터에는 역전파 정보가 거의 전달되지 않게 됩니다.<br/>\n","이런 문제를 **기울기 소실(Vanishing Gradient)**이라고 합니다.\n","\n","반대로 이 값이 1.1 이면 10제곱만해도 2.59배로 커지게 됩니다. 이렇게 되면 시퀀스 앞쪽에 있는 hidden-state 벡터에는 역전파 정보가 과하게 전달됩니다.<br/>\n","이런 문제를 **기울기 폭발(Exploding Gradient)**이라고 합니다."],"metadata":{"id":"xoIPi1zXR39y"}},{"cell_type":"markdown","source":["기울기 정보의 크기가 문제라면,<br/>\n","\"기울기 정보의 크기를 적절하게 조정하여 줄 수 있다면 문제를 해결할 수 있지 않을까?\"라는 생각을 해볼 수 있습니다.\n","\n","이런 아이디어에서 시작하여 고안된 것이 바로 **장단기 기억망(Long-Short Term Memory, LSTM)**입니다."],"metadata":{"id":"baOt1jS1R6-s"}},{"cell_type":"markdown","source":["## 3. LSTM & GRU\n","\n","### LSTM (Long Term Short Memory, 장단기기억망)\n","\n","RNN에 **기울기 정보 크기를 조절하기 위한 Gate를 추가한 모델을 LSTM**이라고 합니다.<br/>\n","요즘에는 단순한 RNN은 사용하지 않고 대부분 LSTM을 사용합니다.\n","\n","RNN이라고 하면 당연히 LSTM이나 이후에 배울 GRU를 지칭할 정도로<br/>\n","LSTM은 Sequential 데이터를 처리하기 위한 대표적인 모델이 되었습니다.<br/>\n","오히려 전에 배운 RNN을 `기본적인 RNN(Vanilla RNN)`이라고 따로 구별하여 표현하기도 합니다."],"metadata":{"id":"EdsJbKMHR8Zl"}},{"cell_type":"markdown","source":["- **LSTM의 구조**\n","\n","먼저, 아래 그림을 통해 LSTM 셀 하나의 구조를 알아보겠습니다.\n","\n","<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F9905CF385BD5F5EC027F20\" width=\"700\"/>"],"metadata":{"id":"gcwb4BN3R-7D"}},{"cell_type":"markdown","source":["RNN의 셀 구조보다 뭔가 상당히 복잡해진 것을 확인할 수 있습니다.\n","\n","위에서 살펴본 것처럼 LSTM이 등장한 배경은 [기울기 소실(Vanishing gradient)](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) 문제를 해결하기 위함이었습니다.\n","\n","\n","LSTM은 기울기 소실 문제를 해결하기 위해 3가지 게이트(gate)를 추가하였습니다. 각 게이트는 다음과 같은 역할을 합니다.\n","\n","1. forget gate ($f_t$): 과거 정보를 얼마나 유지할 것인가?\n","2. input gate ($i_t$) : 새로 입력된 정보는 얼마만큼 활용할 것인가?\n","3. output gate ($o_t$) : 두 정보를 계산하여 나온 출력 정보를 얼마만큼 넘겨줄 것인가?\n","\n","hidden-state 말고도 활성화 함수를 직접 거치지 않는 상태인 cell-state 가 추가되었습니다.<br/>\n","cell-state는 역전파 과정에서 활성화 함수를 거치지 않아 정보 손실이 없기 때문에<br/>\n","**뒷쪽 시퀀스의 정보에 비중을 결정할 수 있으면서 동시에 앞쪽 시퀀스의 정보를 완전히 잃지 않을 수 있습니다.**\n"],"metadata":{"id":"P5BDUaUESA8Q"}},{"cell_type":"markdown","source":["- **LSTM의 역전파**\n","\n","<img src=\"http://i.imgur.com/2BZtc2l.gif\" width=\"700\"/>"],"metadata":{"id":"vyaLbMH1SEAz"}},{"cell_type":"markdown","source":["- **LSTM의 사용**\n","\n","LSTM은 실제로 굉장히 많은 곳에 사용됩니다.\n","\n","여러 언어 모델에서 LSTM을 사용하고 있습니다.<br/>\n","Gate가 적용되지 않은 RNN, 즉 Vanilla RNN은 10~20 단어로 이루어진 문장에 대한 분류/생성/번역 등의 성능이 매우 낮습니다.<br/>\n","Vanilla RNN이 가지고 있는 기울기 소실/폭발 문제 때문입니다.\n","\n","언어 모델 뿐만 아니라 신경망을 활용한 시계열 알고리즘에는 대부분 LSTM을 사용하고 있습니다.\n","\n","### GRU (Gated Recurrent Unit)\n","\n","한편, 이 LSTM의 간소한 버전인 GRU도 가볍게 소개하겠습니다.<br/>\n","그림을 통해 GRU 셀의 구조를 살펴보겠습니다."],"metadata":{"id":"GIkXB-oiSGMm"}},{"cell_type":"markdown","source":["\n","<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F99F0EC3E5BD5F6460255CF\"/>\n","\n","\n","- **GRU 셀의 특징**\n","\n","1. LSTM에서 있었던 cell-state가 사라졌습니다.<br/>\n","cell-state 벡터 $c_t$ ​와 hidden-state 벡터 $h_t$​가 하나의 벡터 $h_t$​로 통일되었습니다.\n","\n","2. 하나의 Gate $z_t$가 forget, input gate를 모두 제어합니다.<br/>\n","$z_t$가 1이면 forget 게이트가 열리고, input 게이트가 닫히게 되는 것과 같은 효과를 나타냅니다.<br/>\n","반대로 $z_t$가 0이면 input 게이트만 열리는 것과 같은 효과를 나타냅니다.\n","\n","3. GRU 셀에서는 output 게이트가 없어졌습니다.<br/>\n","대신에 전체 상태 벡터 $h_t$ 가 각 time-step에서 출력되며, 이전 상태의 $h_{t-1}$ 의 어느 부분이 출력될 지 새롭게 제어하는 Gate인 $r_t$ 가 추가되었습니다."],"metadata":{"id":"sK6lbR0GSKW1"}},{"cell_type":"markdown","source":["### LSTM 코드 실습\n","\n","이제부터 TensorFlow와 Keras를 사용하여 자연어로 RNN을 훈련시켜 보겠습니다.\n","\n","아래는 간단한 LSTM을 사용하여 텍스트 감성 분석을 수행하는 `Tensorflow` 튜토리얼 코드입니다.\n","\n"],"metadata":{"id":"Vpo0y083SMyi"}},{"cell_type":"markdown","source":["- **Keras를 이용한 RNN/LSTM 텍스트 감정 분류(Sentiment classification)**"],"metadata":{"id":"aNmlzHS3SP7l"}},{"cell_type":"markdown","source":["IMDB 영화 리뷰 데이터에 LSTM을 적용하여 감성 분석 태스크를 수행해봅시다."],"metadata":{"id":"oHQLgCIiSRL2"}},{"cell_type":"code","source":["from __future__ import print_function\n","\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.datasets import imdb\n","\n","# 파라미터를 설정합니다.\n","max_features = 20000\n","maxlen = 80\n","batch_size = 32\n","\n","# 데이터를 불러옵니다.\n","print('Loading data...')\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n","print(len(x_train), 'train sequences')\n","print(len(x_test), 'test sequences')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_h45EdzHQwsx","executionInfo":{"status":"ok","timestamp":1679796734644,"user_tz":-540,"elapsed":22911,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"61b74bc1-8b9f-4555-9bc2-71ea338c9be7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data...\n","25000 train sequences\n","25000 test sequences\n"]}]},{"cell_type":"code","source":["# Sequence를 Padding 하여줍니다.\n","print('Pad Sequences (samples x maxlen)')\n","x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n","print('x_train shape: ', x_train.shape)\n","print('x_test shape: ', x_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9R1ZkEb7SSI9","executionInfo":{"status":"ok","timestamp":1679796735339,"user_tz":-540,"elapsed":700,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"48739f60-86d7-4c95-f4ff-491dbb346253"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Pad Sequences (samples x maxlen)\n","x_train shape:  (25000, 80)\n","x_test shape:  (25000, 80)\n"]}]},{"cell_type":"code","source":["x_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JsmNg7fVSTPu","executionInfo":{"status":"ok","timestamp":1679796735340,"user_tz":-540,"elapsed":4,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"6cf67a52-f970-4e53-9565-c34623c5ff5d"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n","          71,    43,   530,   476,    26,   400,   317,    46,     7,\n","           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n","         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n","        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n","         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n","         224,    92,    25,   104,     4,   226,    65,    16,    38,\n","        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n","         103,    32,    15,    16,  5345,    19,   178,    32],\n","      dtype=int32)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# model을 정의합니다.\n","\"\"\"\n","keras의 기본 Embedding 벡터를 사용하였으며\n","LSTM 층에 dropout/recurrent_dropout을 적용하였습니다.\n","\"\"\"\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Embedding(max_features, 128), # Embedding Layer를 거친 후의 shape : (batch_size, maxlen, embedding_size=128)\n","  tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2), # LSTM Layer를 거친 후의 shape : (batch_size, 1, hidden_size=128)\n","  tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='adam', \n","              metrics=['accuracy'])\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CC6WON33SUBT","executionInfo":{"status":"ok","timestamp":1679796739216,"user_tz":-540,"elapsed":3879,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"417fb46b-a055-4e64-c9d0-677a7bd1e831"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 128)         2560000   \n","                                                                 \n"," lstm (LSTM)                 (None, 128)               131584    \n","                                                                 \n"," dense (Dense)               (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 2,691,713\n","Trainable params: 2,691,713\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["unicorns = model.fit(x_train, y_train,\n","          batch_size=batch_size, \n","          epochs=3, \n","          validation_data=(x_test,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTcyFXn-SUx_","executionInfo":{"status":"ok","timestamp":1679797727408,"user_tz":-540,"elapsed":988200,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"a8b12b4d-49e1-444a-d122-2288c7435c1c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","782/782 [==============================] - 332s 416ms/step - loss: 0.4247 - accuracy: 0.8044 - val_loss: 0.3555 - val_accuracy: 0.8434\n","Epoch 2/3\n","782/782 [==============================] - 303s 387ms/step - loss: 0.2556 - accuracy: 0.8983 - val_loss: 0.4039 - val_accuracy: 0.8377\n","Epoch 3/3\n","782/782 [==============================] - 307s 392ms/step - loss: 0.1650 - accuracy: 0.9371 - val_loss: 0.4199 - val_accuracy: 0.8185\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot training & validation loss values\n","plt.plot(unicorns.history['loss'])\n","plt.plot(unicorns.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Test'], loc='upper left')\n","plt.show();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"7CBkEi7TSWXy","executionInfo":{"status":"ok","timestamp":1679797727821,"user_tz":-540,"elapsed":429,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"579d64fa-1a98-40d5-a3e0-f7bde8a5c138"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["- **Keras를 이용한 LSTM 텍스트 생성기**"],"metadata":{"id":"548uCadySYWg"}},{"cell_type":"markdown","source":["LSTM을 사용하면 첫 번째 시간에 소개드렸던 자연어 생성 태스크도 수행할 수 있습니다.\n","\n","니체(Friedrich Nietzsche)의 글을 학습하여 비슷한 글을 생성해내는 튜토리얼 코드를 실행하여 텍스트 생성 실습을 해보겠습니다.\n","(주의 : 완료되기까지 시간이 매우 오래 걸립니다.)\n"],"metadata":{"id":"DFsB10xiSaEz"}},{"cell_type":"code","source":["# 라이브러리, 데이터 불러오기\n","from __future__ import print_function\n","from keras.callbacks import LambdaCallback\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.optimizers import RMSprop\n","from keras.utils.data_utils import get_file\n","import numpy as np\n","import random\n","import sys\n","import io\n","\n","path = get_file(\n","    'nietzsche.txt',\n","    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","with io.open(path, encoding='utf-8') as f:\n","    text = f.read().lower()\n","print('corpus length:', len(text))\n","\n","chars = sorted(list(set(text)))\n","print('total chars:', len(chars))\n","char_indices = dict((c, i) for i, c in enumerate(chars))\n","indices_char = dict((i, c) for i, c in enumerate(chars))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae6d70fJSZYy","executionInfo":{"status":"ok","timestamp":1679797727821,"user_tz":-540,"elapsed":8,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"21ebee67-ec4b-4584-96e5-5a658a5c33a6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["corpus length: 600893\n","total chars: 57\n"]}]},{"cell_type":"code","source":["# max length를 이용하여 문자열의 크기 정렬\n","maxlen = 40\n","step = 3\n","\n","sentences = []\n","next_chars = []\n","\n","for i in range(0, len(text) - maxlen, step):\n","    sentences.append(text[i: i + maxlen])\n","    next_chars.append(text[i + maxlen])\n","print('nb sequences:', len(sentences))\n","\n","print('Vectorization...')\n","\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rdo62wlSbs3","executionInfo":{"status":"ok","timestamp":1679797730058,"user_tz":-540,"elapsed":2243,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"7501e85e-3d7b-452d-e364-c76f62b5592e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["nb sequences: 200285\n","Vectorization...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-2859ddfaf318>:15: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","<ipython-input-9-2859ddfaf318>:16: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"]}]},{"cell_type":"code","source":["# LSTM 모델을 제작합니다.\n","print('Build model...')\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(maxlen, len(chars)))) # maxlen 길이의 문장이고, 원-핫벡터로 이루어진 데이터가 input으로 들어온다\n","model.add(Dense(len(chars), activation='softmax'))\n","\n","optimizer = RMSprop(learning_rate=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcKARr6fScvm","executionInfo":{"status":"ok","timestamp":1679797730059,"user_tz":-540,"elapsed":5,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"dc252d22-fc3c-467a-ffe0-e7e3253c232f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Build model...\n"]}]},{"cell_type":"code","source":["# sample 문장을 생성하도록 하는 함수입니다.\n","def sample(preds, temperature=1.0):\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","\n","# Epoch가 끝날 때마다 sample 문장을 생성하는 함수입니다.\n","def on_epoch_end(epoch, _):\n","    print()\n","    print('----- Generating text after Epoch: %d' % epoch)\n","\n","    start_index = random.randint(0, len(text) - maxlen - 1)\n","\n","    # temperature를 조정하여 단어 선택 시 다양성을 부여합니다.\n","    \"\"\"\n","    https://3months.tistory.com/491, https://stackoverflow.com/questions/58764619/why-should-we-use-temperature-in-softmax\n","    위 링크들을 참조하여 temperature(diversity) 값이 커질수록\n","    단어 선택이 어떻게 변할 지에 대해서 알아보도록 합시다.\n","    \"\"\" \n","    for diversity in [0.2, 0.5, 1.0, 1.2]:\n","        print('----- diversity:', diversity)\n","\n","        generated = ''\n","        sentence = text[start_index: start_index + maxlen]\n","        generated += sentence\n","        print('----- Generating with seed: \"' + sentence + '\"')\n","        sys.stdout.write(generated)\n","\n","        for i in range(400):\n","            x_pred = np.zeros((1, maxlen, len(chars)))\n","            for t, char in enumerate(sentence):\n","                x_pred[0, t, char_indices[char]] = 1.\n","\n","            preds = model.predict(x_pred, verbose=0)[0]\n","            next_index = sample(preds, diversity)\n","            next_char = indices_char[next_index]\n","\n","            generated += next_char\n","            sentence = sentence[1:] + next_char\n","\n","            sys.stdout.write(next_char)\n","            sys.stdout.flush()\n","        print()\n","\n","print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"],"metadata":{"id":"GLg96tEeSddo","executionInfo":{"status":"ok","timestamp":1679797730059,"user_tz":-540,"elapsed":4,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["(주의 : 아래 셀은 시간이 매우 오래 걸립니다. 실행 시 주의해 주세요.)\n","\n","시간 관계상 epochs 을 대폭 줄여서 수행"],"metadata":{"id":"p5tHptdLSfZ5"}},{"cell_type":"code","source":["model.fit(x, y,\n","          batch_size=128,\n","          epochs=5,  # 60\n","          callbacks=[print_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DsUNhAsrSeEn","executionInfo":{"status":"ok","timestamp":1679798233525,"user_tz":-540,"elapsed":503071,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"c8ca20fd-c923-4292-c594-88e27bec9105"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1560/1565 [============================>.] - ETA: 0s - loss: 1.9683\n","----- Generating text after Epoch: 0\n","----- diversity: 0.2\n","----- Generating with seed: \"ards our god: he is not permitted to\n","sin\"\n","ards our god: he is not permitted to\n","sind in the superfor in the sude of the such and the form of the such and interlang the superfor the such and the superfor and the such and the such and such and the sume to have the such and the such and the something the present to his consident to the such and the indere of the superfor the superfor the super of the such and the something the subself the such and the such and the such and the such\n","----- diversity: 0.5\n","----- Generating with seed: \"ards our god: he is not permitted to\n","sin\"\n","ards our god: he is not permitted to\n","sind. the sugn and the with who wast and self-with are sures in consideration of his and stronger the something the and the had expent of the sudder to a person and the superficinsless is not present of the bid and when the soiling in the the or not the itself the consise and who super--and the righter and doral reciest of such not in the sumposific of the had and and things is the for itself--and so\n","----- diversity: 1.0\n","----- Generating with seed: \"ards our god: he is not permitted to\n","sin\"\n","ards our god: he is not permitted to\n","singity--but evation of thesely-exinsessions, and clasm of the altire suppory \"\"recares of theer heivess!htring would co-moding and it that xervody\n","every and sid\"rorn the wellous \"so\n","from highest wiffer not\n","the the saper\n","hay the soilitys is neaut andahely--a ant who wap an outizal the said, very the tdisificacest\n","itself, to our suim tand wera, petromed, for himmelity; a prisiny soor of imonted someth\n","----- diversity: 1.2\n","----- Generating with seed: \"ards our god: he is not permitted to\n","sin\"\n","ards our god: he is not permitted to\n","sinngect belongy pachour\n","seche im, wavony\n","at reedurceriused everytictardhe, ad. only\n","the ow paws the evrow, a\n","nlerssary hrowe we\n","talks\n","we arong which\n","nlt man in puculy inarfoction.\n","\n","\n","59\n","\n","=enking\n","sensifisy as ow sure\n","must ilspow\n","herlious hiader, omeros! they bat religiops unaver languand. the will love much\n","fokly!. --what not  appauste with uenorigins! ordies. \"at ageituous this its hadpe, oulde ewaph\n","1565/1565 [==============================] - 101s 63ms/step - loss: 1.9677\n","Epoch 2/5\n","1565/1565 [==============================] - ETA: 0s - loss: 1.6190\n","----- Generating text after Epoch: 1\n","----- diversity: 0.2\n","----- Generating with seed: \"e complicated mechanism of our\n","\"firmamen\"\n","e complicated mechanism of our\n","\"firmament the senses of the conserved to the presint the highest the the sension of the preserves the the precisely the endion of the present the end the moral senses of the morality and the which and the consideration of the morality and and the present the the present the presint the contrarical and in the senses the senses the highest the for the present the the every and the conserved to the present t\n","----- diversity: 0.5\n","----- Generating with seed: \"e complicated mechanism of our\n","\"firmamen\"\n","e complicated mechanism of our\n","\"firmament of which which recognize and and man and art for and manking, in the philosophers of the reprectant precised the way the charaction the shill from and be things: and the from his free of his deversted and shall and the present to which the end the standard, which precisely of morality and the reasing the\n","sire the which the priblity and the considers of and as a the thingly as superficism of his \n","----- diversity: 1.0\n","----- Generating with seed: \"e complicated mechanism of our\n","\"firmamen\"\n","e complicated mechanism of our\n","\"firmamens of\n","great ciusire, in the christian senful\n","\n","would weraphy non where highing is, hibery the, it is\n","old at\n","torbplied. he his op-considerual, very not   from something and which rimity inclines, and be!\n","fill wills--alves brajeen of poders, itself say are dilfly vection for his bethered uphed and will natures and thinged of the the \"itsicared to ochuin for invints of cont. much was not opgoners, come\n","----- diversity: 1.2\n","----- Generating with seed: \"e complicated mechanism of our\n","\"firmamen\"\n","e complicated mechanism of our\n","\"firmament the must both nciencitation the\n","collerior far at it\n","distreanes.i, forcersmant highest imit, in their connected by\n","this meents it the it, it. nei indulcef. other fore) whether such amon of us necessity may\n","a ob(to reinling thing; perhaps, of the highe the not what valuec drdisitsmle-probuuts doupper, are the beenic and custed to the oncent and woman around\n","seefs to it at and ha gornded as becimit\n","1565/1565 [==============================] - 100s 64ms/step - loss: 1.6190\n","Epoch 3/5\n","1556/1565 [============================>.] - ETA: 0s - loss: 1.5325\n","----- Generating text after Epoch: 2\n","----- diversity: 0.2\n","----- Generating with seed: \"rlessness of gaze, as\n","courage and sternn\"\n","rlessness of gaze, as\n","courage and sternness and the such a such a so the such a surponders of the power of the present and the present and the perhaps a present as the such as the present and all the all the self-desires and the extent of the perhaps a present and in the supersonion of the such presence of the such as the most and as a perhaps a such a subject of the subjection of the belief to the and so the subject of the freedom of t\n","----- diversity: 0.5\n","----- Generating with seed: \"rlessness of gaze, as\n","courage and sternn\"\n","rlessness of gaze, as\n","courage and sternness and instinction itself that not in the such conscience as the supersonion, and a an instinctions, and the present and who such also we experience of the subject of the way the succession and new not the conscience of the good to for the present us of surponing of the sast the subject and lookerful standards and the pressly elses and in man hamanity of which as a such individual hemminitation o\n","----- diversity: 1.0\n","----- Generating with seed: \"rlessness of gaze, as\n","courage and sternn\"\n","rlessness of gaze, as\n","courage and sternness, course, of muchjerationsly easy\n","good\n","\"umen, thereby in demankered for deminated.l inde. which he srin(minbuline for ma? the\n","excessed the dispenserly only, uncalling epeects\n","bewo gow instinction, and most moralifi. and ye\n","many,\n","specharile: fins women old and read less\n","singurg condition at the fighte of\n","canajary didias and\n","subject\" to imexsuition and trues. is abtrainate wold thore unto which d\n","----- diversity: 1.2\n","----- Generating with seed: \"rlessness of gaze, as\n","courage and sternn\"\n","rlessness of gaze, as\n","courage and sternness, in thef a engaropher, unresponjoination of\n","sortmby attent heringures.m\n","us mead for an runtlingaring: even great glibef, cually also,\n","honesif is kind\n","hereliously because\n","excessophifi es a resolictice wis closephause one the suffering is nefyerdhed too our actws\n","gictune, other wills: goovby basys fundd theme\n","physiof--as exist\n","eprareaging me by state, dovetive pricepoourg6ly devountmen, only a c\n","1565/1565 [==============================] - 99s 64ms/step - loss: 1.5325\n","Epoch 4/5\n","1555/1565 [============================>.] - ETA: 0s - loss: 1.4878\n","----- Generating text after Epoch: 3\n","----- diversity: 0.2\n","----- Generating with seed: \"nfluence of\n","respectable but mediocre eng\"\n","nfluence of\n","respectable but mediocre engation of the strength and experience of the powerful and all the high the step and art and experience of the free of the sense and as the sense of the free conscious and experience of the subvicity of the powerful and in the procedies of the sense of the procedistion of the problem of the most pround the conscience of the strength of the present of the sense of the subjection of the problem of the\n","----- diversity: 0.5\n","----- Generating with seed: \"nfluence of\n","respectable but mediocre eng\"\n","nfluence of\n","respectable but mediocre englanted to commanding of moral capable to conception of success, of a more in himself and morality of god as an artifications as the hearting, and a sourt as the consciously and as a thing in all the happiness and proproces to the capaced to the experience of the first men to fact to doounger to the powerful, the deferently seciously and all as from the lease to self even a presenture and all the w\n","----- diversity: 1.0\n","----- Generating with seed: \"nfluence of\n","respectable but mediocre eng\"\n","nfluence of\n","respectable but mediocre engaile moence as the mid of my finally leasy\n","evinmed to\n","guert may when the c. !\" own life. the listne the made deventer, is glanes,\"-velse \"will in stally and among science inclitire and self fact, and unconsided that that is\n","to such sair men: here accustounists. the leves otwing to orse cempleity to kild and philosophers, a single referers are appeditudared as so about contratic \"is extal, every co\n","----- diversity: 1.2\n","----- Generating with seed: \"nfluence of\n","respectable but mediocre eng\"\n","nfluence of\n","respectable but mediocre englard yet windless,\n","cuted\n","at molly,\n","because perhaps, but understanded the sagicice\n","of enly was a name of bners like to remond certainly\n","yet yous bapidis to ba better opine to bein only rewaken.\n","\n","\n"," f\n","orical sight and\n","chadmantilies, pentually expertion, disaly acpediation of doiwgion of\n","unid ones-are zenounning tean of continment that the begiintary\n","incroate culture\n","a\n","for the hightenests specially do\n","1565/1565 [==============================] - 102s 65ms/step - loss: 1.4881\n","Epoch 5/5\n","1564/1565 [============================>.] - ETA: 0s - loss: 1.4579\n","----- Generating text after Epoch: 4\n","----- diversity: 0.2\n","----- Generating with seed: \"ate\n","these little tokens of kindly feelin\"\n","ate\n","these little tokens of kindly feelings, and and the sentiment and subject of the senses to the world and are the sense of the sentiment the world it belongs the world and the sentiment and and also the subject of the sentiment to the sense and the and and the sentiment the sense of the strange and the probably the conception of the sentiment of the sense of the sentiment and as the senses to the sense of the sentiment the standard a\n","----- diversity: 0.5\n","----- Generating with seed: \"ate\n","these little tokens of kindly feelin\"\n","ate\n","these little tokens of kindly feelings of as conscience and and more that all the better and in the actions here and power of the finally and innereations of a saint is the former and actions, and all the plensuse of the same and the world-whom also the present the feeling of the probably whold and victure to the heart that the thee mand the wait that the stand their courally to the same appears and inditations of a still and what i\n","----- diversity: 1.0\n","----- Generating with seed: \"ate\n","these little tokens of kindly feelin\"\n","ate\n","these little tokens of kindly feelings undepsratione, driatly wit is time sense of the world it bast soul. thereby so bad be-as only be mastiman time to\n","all under the heart. taste although\n","are the self-alright a minisol characterid not but huutifuce at appearance, consciples, sale, at onceatured also, the case. into the ascrusion, also,\n","in does they grate, and prehaits nued the grant\n","self-concealal, cotally and influences \"cate that\n","----- diversity: 1.2\n","----- Generating with seed: \"ate\n","these little tokens of kindly feelin\"\n","ate\n","these little tokens of kindly feelings is humsoldegr, a national midvash.f-arboudm procideques\"--he-a, sames; has welconle badsening\n","and were he man it istersusiacity\".h--!                      every belief--thenementumety asracal what\n","so, ierbo; i a bhild, and it like the hathing general sightings to respensive, readrative hali-dvenge, so are fundamen onleituje an as, still morality. narsy for\n","which,\n","we havois clasially therejble\" \n","1565/1565 [==============================] - 101s 64ms/step - loss: 1.4578\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1c5e3f5cd0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## 4. RNN 구조에 Attention 적용하기"],"metadata":{"id":"rulo2Nv1SjSR"}},{"cell_type":"markdown","source":["RNN이 가진 가장 큰 단점 중 하나는 기울기 소실로부터 나타나는 **장기 의존성(Long-term dependency)** 문제입니다.<br/>\n","장기 의존성 문제란 문장이 길어질 경우 앞 단어의 정보를 잃어버리게 되는 현상입니다.<br/>\n","장기 의존성 문제를 해결하기 위해 나온 것이 셀 구조를 개선한 LSTM과 GRU입니다.<br/>\n","기계 번역에서 RNN 기반의 모델(LSTM, GRU)이 단어를 처리하는 방법은 아래와 같다고 할 수 있습니다."],"metadata":{"id":"myveLmYOSkh0"}},{"cell_type":"markdown","source":["<img src=\"https://user-images.githubusercontent.com/45377884/86040995-f27b4800-ba7f-11ea-8ca1-67b2517573eb.gif\" alt=\"seq2seq_6\" width=\"800\" />"],"metadata":{"id":"8g2vFozdSl7g"}},{"cell_type":"markdown","source":["### Attention의 등장"],"metadata":{"id":"le2kGP5rSnZd"}},{"cell_type":"markdown","source":["위 구조의 문제는 고정 길이의 hidden-state 벡터에 모든 단어의 의미를 담아야 한다는 점입니다.<br/>\n","아무리 LSTM, GRU가 장기 의존성 문제를 개선하였더라도 문장이 매우 길어지면(30-50 단어) 모든 단어 정보를 고정 길이의 hidden-state 벡터에 담기 어렵습니다.<br/>\n","이런 문제를 해결하기 위해서 고안된 방법이 바로 **Attention(어텐션)** 입니다."],"metadata":{"id":"B_0fSC8sSoPp"}},{"cell_type":"markdown","source":["<img src=\"https://user-images.githubusercontent.com/45377884/86040873-b942d800-ba7f-11ea-9f59-ee23923f777e.gif\" alt=\"seq2seq_7\" width=\"800\" />"],"metadata":{"id":"bVU7sqM9SpOP"}},{"cell_type":"markdown","source":["Attention은 각 인코더의 Time-step 마다 생성되는 hidden-state 벡터를 간직합니다.<br/>\n","입력 단어가 N개라면 N개의 hidden-state 벡터를 모두 간직하게 됩니다.<br/>\n","모든 단어가 입력되면 생성된 hidden-state 벡터를 모두 디코더에 넘겨줍니다.\n","\n","디코더는 받은 N개의 hidden-state 벡터를 어떻게 활용할까요?"],"metadata":{"id":"yESrOFGpSqUm"}},{"cell_type":"markdown","source":["- **검색 시스템의 아이디어 둘러보기**\n","\n","잠시 돌아가 검색 시스템에 대해 알아봅시다.<br/>\n","아래는 구글에서 _\"what is attention in nlp\"_ 라는 검색어를 구글에 입력했을 때의 검색 결과를 나타낸 이미지입니다.\n","\n","<img src=\"https://i.imgur.com/JdCQr1l.png\" alt=\"retrieval_system\" width=\"600\" />\n","\n","그림에서 볼 수 있듯이 검색 시스템은 아래와 같은 3단계를 거쳐 작동합니다.\n","\n","1. 찾고자 하는 정보에 대한 검색어(Query)를 입력합니다.\n","2. 검색 엔진은 검색어와 가장 비슷한 키워드(Key)를 찾습니다.\n","3. 그리고 해당 키워드(Key)와 연결된 페이지(Value)를 보여줍니다."],"metadata":{"id":"KBGRHX_ESrVU"}},{"cell_type":"code","source":["# 더 알아보기 : 파이썬의 딕셔너리도 비슷한 형태로 작동합니다.\n","# Query('a')를 던지면 딕셔너리에서 동일한 Key('a')를 찾은 뒤 Value(123)을 반환합니다.\n","\n","dict1 = {'a':123, 'b':425, 'c':236, 'd':945}\n","dict1['a']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfPaQz_1Si4o","executionInfo":{"status":"ok","timestamp":1679798233526,"user_tz":-540,"elapsed":8,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"9c218455-652f-4d00-cbec-ac434f5180e3"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["123"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["### 디코더에서 Attention이 동작하는 방법"],"metadata":{"id":"RvB1IgeiStej"}},{"cell_type":"markdown","source":["디코더에서 단어를 생성하는 과정을 알아보겠습니다.\n","\n","디코더의 각 time-step 마다의 hidden-state 벡터는 쿼리(query)로 작용합니다.<br/>\n","인코더에서 넘어온 N개의 hidden-state 벡터를 키(key)로 여기고 이들과의 연관성을 계산합니다.<br/>\n","이 때 계산은 내적(dot-product)을 사용하고 내적의 결과를 Attention 가중치로 사용합니다.<br/>\n","\n","아래는 디코더 첫 단어 \"I\"(`Time-step 4`)에 대한 어텐션 가중치가 구해지는 과정입니다."],"metadata":{"id":"uYVNM8jCSuTX"}},{"cell_type":"markdown","source":["<img src=\"https://i.imgur.com/gNcbamV.png\" title=\"source: imgur.com\" width=\"800\" /></a>"],"metadata":{"id":"VhFyCIU5SvLQ"}},{"cell_type":"markdown","source":["1. 쿼리(Query)인 디코더의 hidden-state 벡터, 키(Key)인 인코더에서 넘어온 hidden-state 벡터를 준비합니다.\n","2. 각각의 벡터를 내적한 값을 구합니다.\n","3. 이 값에 소프트맥스(softmax) 함수를 취해줍니다.\n","4. 소프트맥스를 취하여 나온 값에 밸류(Value)에 해당하는 인코더에서 넘어온 hidden-state 벡터를 곱해줍니다. \n","5. 이 벡터를 모두 더해줍니다. 이 벡터의 성분 중에는 쿼리-키 연관성이 높은 밸류 벡터의 성분이 더 많이 들어있게 됩니다.\n","6. (그림에는 나와있지 않지만) 최종적으로 5에서 생성된 벡터와 디코더의 hidden-state 벡터를 사용하여 출력 단어를 결정하게 됩니다."],"metadata":{"id":"-OC2U_jzSwSQ"}},{"cell_type":"markdown","source":["디코더는 인코더에서 넘어온 모든 Hidden state 벡터에 대해 위와 같은 계산을 실시합니다.<br/>\n","그렇기 때문에 Time-step마다 출력할 단어가 어떤 인코더의 어떤 단어 정보와 연관되어 있는지, 즉 어떤 단어에 **집중(Attention)**할 지를 알 수 있습니다.<br/>\n","Attention을 활용하면 디코더가 인코더에 입력되는 모든 단어의 정보를 활용할 수 있기 때문에 장기 의존성 문제를 해결할 수 있습니다.\n","\n","아래는 예시로 제시되었던 문장을 번역(**`Je suis etudiant => I am a student`**)했을 때 각 단어마다의 Attention 스코어를 시각화 한 그림입니다.<br/>\n","\n","> _\"I\"_ -> _\"Je\"_ <br/>\n","> _\"am\"_ -> _\"suis\"_<br/>\n","> _\"a\"_ -> _\"suis\", \"etudiant\"_<br/>\n","> _\"student\"_ -> _\"etudiant\"_\n","\n","왼쪽 단어가 생성될 때 오른쪽 단어와 연관되어 있음을 확인할 수 있습니다. \n"],"metadata":{"id":"0SVddwvMSwy_"}},{"cell_type":"markdown","source":["<img src=\"https://user-images.githubusercontent.com/45377884/86047018-29a22700-ba89-11ea-98ee-a90b2fb70a23.gif\" alt=\"attn_visualization\" width=\"500\" />"],"metadata":{"id":"xtKqIrFiSycx"}},{"cell_type":"markdown","source":["### RNN(LSTM) with Attention 코드 실습\n","\n","`Tensorflow` 튜토리얼 코드를 사용하여 Attention이 어떻게 적용되는 지 알아보도록 하겠습니다."],"metadata":{"id":"mgd185LYSz1u"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time"],"metadata":{"id":"NeX_XCQOSsoW","executionInfo":{"status":"ok","timestamp":1679798234796,"user_tz":-540,"elapsed":1275,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 데이터셋을 다운로드합니다.\n","path_to_zip = tf.keras.utils.get_file(\n","    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n","    extract=True)\n","\n","path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ldr4O3mIS1Jo","executionInfo":{"status":"ok","timestamp":1679798234796,"user_tz":-540,"elapsed":9,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"609779f1-4b7d-4a99-83c6-c714b67f3a42"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","2638744/2638744 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# 유니코드 파일을 아스키코드로 변환하는 함수입니다.\n","def unicode_to_ascii(s):\n","  return ''.join(c for c in unicodedata.normalize('NFD', s)\n","                 if unicodedata.category(c) != 'Mn')\n","\n","\n","def preprocess_sentence(w):\n","  w = unicode_to_ascii(w.lower().strip())\n","\n","  # creating a space between a word and the punctuation following it\n","  # eg: \"he is a boy.\" => \"he is a boy .\"\n","  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","  w = re.sub(r'[\" \"]+', \" \", w)\n","\n","  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n","\n","  w = w.strip()\n","\n","  # adding a start and an end token to the sentence\n","  # so that the model know when to start and stop predicting.\n","  w = '<start> ' + w + ' <end>'\n","  return w"],"metadata":{"id":"hbW9osueS1we","executionInfo":{"status":"ok","timestamp":1679798234796,"user_tz":-540,"elapsed":6,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["en_sentence = u\"May I borrow this book?\"\n","sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n","print(preprocess_sentence(en_sentence))\n","print(preprocess_sentence(sp_sentence).encode('utf-8'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_0P7Fb2QS2eZ","executionInfo":{"status":"ok","timestamp":1679798234796,"user_tz":-540,"elapsed":6,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"261fe008-e786-4630-bb69-66f4eecd721c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["<start> may i borrow this book ? <end>\n","b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"]}]},{"cell_type":"code","source":["# 1. Remove the accents\n","# 2. Clean the sentences\n","# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n","def create_dataset(path, num_examples):\n","  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n","\n","  word_pairs = [[preprocess_sentence(w) for w in line.split('\\t')]\n","                for line in lines[:num_examples]]\n","\n","  return zip(*word_pairs)"],"metadata":{"id":"K8m9-hF7S3lr","executionInfo":{"status":"ok","timestamp":1679798234796,"user_tz":-540,"elapsed":4,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["en, sp = create_dataset(path_to_file, None)\n","print(en[-1])\n","print(sp[-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xb3Wp23nS4DE","executionInfo":{"status":"ok","timestamp":1679798239327,"user_tz":-540,"elapsed":4132,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"ac72534a-83b0-4caa-dbf8-e850d80e698d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n","<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"]}]},{"cell_type":"code","source":["def tokenize(lang):\n","  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","  lang_tokenizer.fit_on_texts(lang)\n","\n","  tensor = lang_tokenizer.texts_to_sequences(lang)\n","\n","  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n","                                                         padding='post')\n","\n","  return tensor, lang_tokenizer"],"metadata":{"id":"L5oclJlmS4oh","executionInfo":{"status":"ok","timestamp":1679798239327,"user_tz":-540,"elapsed":3,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# 2개 언어이기 때문에, tokenizer가 각각의 언어별로 따로 필요합니다.\n","def load_dataset(path, num_examples=None):\n","  # creating cleaned input, output pairs\n","  targ_lang, inp_lang = create_dataset(path, num_examples)\n","\n","  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n","  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n","\n","  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"],"metadata":{"id":"mHbWxh9GS5MO","executionInfo":{"status":"ok","timestamp":1679798239327,"user_tz":-540,"elapsed":2,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# load할 dataset의 개수를 30000으로 설정\n","num_examples = 30000\n","input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n","\n","# target과 input의 최대 길이 구하기(문장 최대 길이)\n","max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"],"metadata":{"id":"TPj9kjd0S5xL","executionInfo":{"status":"ok","timestamp":1679798241846,"user_tz":-540,"elapsed":2521,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# 8:2 비율로 train-test split 진행\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n","\n","# 데이터 개수 뽑아보기\n","print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fmHvA0cS6nS","executionInfo":{"status":"ok","timestamp":1679798241846,"user_tz":-540,"elapsed":15,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"e9ffa8f8-49d7-42dd-e3d7-dfff03a5a6e4"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["24000 24000 6000 6000\n"]}]},{"cell_type":"markdown","source":["- 구조와 관련된 파라미터 설정하기"],"metadata":{"id":"fU4NTg1rS76j"}},{"cell_type":"code","source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n","embedding_dim = 256\n","units = 1024\n","vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","\n","# tf.data.Dataset -> 텐서플로우에서 제공하는 Dataset 클래스입니다.\n","# Dataset 클래스는 배치 구성, 데이터셋 셔플, 윈도우 구현, 변환 함수 적용 등 다양한 기능을 제공합니다.\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"5G3HKuLcS7Ku","executionInfo":{"status":"ok","timestamp":1679798241846,"user_tz":-540,"elapsed":14,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# 첫 번째 배치 뽑아보기\n","# input_batch의 경우, 총 64개 데이터로 이루어져 있고, 1개 문장이 16개 단어로 이루어져 있습니다.\n","example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIvM8Z8tS8i5","executionInfo":{"status":"ok","timestamp":1679798241847,"user_tz":-540,"elapsed":15,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"41abadda-0ada-48be-eac4-8077a78268c8"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 16]), TensorShape([64, 11]))"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["- 인코더 구현하기"],"metadata":{"id":"YPY_HNhwS9zH"}},{"cell_type":"code","source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.enc_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","\n","  def call(self, x, hidden):\n","    # |x| = (batch_sz, seq_len)\n","    x = self.embedding(x) # |x| = (batch_sz, seq_len, embedding_dim)\n","    output, state = self.gru(x, initial_state=hidden)\n","    return output, state\n","\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_sz, self.enc_units))"],"metadata":{"id":"k43tVvc-S9EM","executionInfo":{"status":"ok","timestamp":1679798241847,"user_tz":-540,"elapsed":13,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# sample input을 통해 Encoder 레이어 결과값의 shape을 확인해보겠습니다\n","encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","# sample input\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","print('Encoder output shape: (batch size, sequence length, units)', sample_output.shape)\n","print('Encoder Hidden state shape: (batch size, units)', sample_hidden.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-6-2tHoAS-mN","executionInfo":{"status":"ok","timestamp":1679798241847,"user_tz":-540,"elapsed":12,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"e4400cc3-457d-47e8-9f39-0370447e0fd2"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"]}]},{"cell_type":"code","source":["class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","    # query hidden state shape == (batch_size, hidden size)\n","    # query_with_time_axis shape == (batch_size, 1, hidden size)\n","    # values shape == (batch_size, max_len, hidden size)\n","    # we are doing this to broadcast addition along the time axis to calculate the score\n","    query_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(query_with_time_axis) + self.W2(values)))\n","    # W1(query_with_time_axis) == (batch_size, 1, units)\n","    # W2(values) == (batch_size, max_len, units)\n","    # W1(query_with_time_axis) + W2(values) == (batch_size, max_len, units)\n","    # V(tf.nn.tanh(W1(query_with_time_axis) + W2(values))) == (batch_size, max_len, 1)\n","\n","    attention_weights = tf.nn.softmax(score, axis=1) # attention_weights == (batch_size, max_length, 1)\n","\n","    context_vector = attention_weights * values # context_vector == (batch_size, max_len, hidden_size)\n","    context_vector = tf.reduce_sum(context_vector, axis=1) # context_vector == (batch_size, hidden_size)\n","\n","    return context_vector, attention_weights"],"metadata":{"id":"lKVIMWyVS_Wh","executionInfo":{"status":"ok","timestamp":1679798241847,"user_tz":-540,"elapsed":10,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["attention_layer = BahdanauAttention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units)\", attention_result.shape)\n","print(\"Attention weights shape: (batch_size, sequence_length, 1)\", attention_weights.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6eiBl0bzS__R","executionInfo":{"status":"ok","timestamp":1679798242226,"user_tz":-540,"elapsed":389,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"06e61e6d-e11b-4b62-b3b4-5bca9fc2702f"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"]}]},{"cell_type":"markdown","source":["- **디코더 구현**"],"metadata":{"id":"O3pbf7T1TBhR"}},{"cell_type":"code","source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # used for attention\n","    self.attention = BahdanauAttention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # x == (batch_size, 1)\n","    # hidden == (batch_size, hidden_size)\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","    # context_vector == (batch_size, hidden_size)\n","    # attention_weights == (batch_size, max_length, 1)\n","\n","    x = self.embedding(x) # x == (batch_size, 1, embedding_dim)\n","\n","    # tf.expand_dims(context_vector, 1) == (batch_size, 1, hidden_size)\n","    # tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) == (batch_size, 1, embedding_dim+hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    # output == (batch_size, 1, hidden_size)\n","    # state == (batch_size, hidden_size)\n","    output, state = self.gru(x)\n","\n","    \n","    output = tf.reshape(output, (-1, output.shape[2])) # output  == (batch_size * 1, hidden_size)\n","\n","    x = self.fc(output) # x == (batch_size, vocab)\n","\n","    return x, state, attention_weights"],"metadata":{"id":"jNmCktDMTAyW","executionInfo":{"status":"ok","timestamp":1679798242227,"user_tz":-540,"elapsed":6,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print('Decoder output shape: (batch_size, vocab size)', sample_decoder_output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdVDrsPVTCLB","executionInfo":{"status":"ok","timestamp":1679798242227,"user_tz":-540,"elapsed":6,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"7421b906-2378-47d5-f84f-2c3b2a24632e"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder output shape: (batch_size, vocab size) (64, 4935)\n"]}]},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n","                                                            reduction='none')\n","\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"metadata":{"id":"FB5Mms-uTC_P","executionInfo":{"status":"ok","timestamp":1679798242227,"user_tz":-540,"elapsed":4,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["Teacher Forcing\n","- seq2seq에서 decoder의 예측값이 아닌 실제 정답인 target을 다음 타임 스텝의 입력으로 넣어주는 방법을 Teacher Forcing이라고 합니다.\n","- 장점\n","  - 만약 decoder가 엉뚱한 대답을 내놓더라도, 학습 시 실제 정답을 넣어주기 때문에 seq2seq 학습에 안정성을 더해줍니다.\n","- 단점\n","  - 실제 학습과 추론 코드를 각각 구성해야 합니다.\n","  - 학습과 추론 사이의 괴리가 존재합니다.\n"],"metadata":{"id":"pUIG8cFaTESl"}},{"cell_type":"code","source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","      # passing enc_output to the decoder\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # using teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"metadata":{"id":"rhNxm3q5TDf6","executionInfo":{"status":"ok","timestamp":1679798242228,"user_tz":-540,"elapsed":4,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 10\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","      \n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_i_u50hTGrA","executionInfo":{"status":"ok","timestamp":1679798528633,"user_tz":-540,"elapsed":286409,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"07dd8ea5-137d-48ae-8c42-bceb9010cdbe"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0 Loss 4.5539\n","Epoch 1 Batch 100 Loss 2.1030\n","Epoch 1 Batch 200 Loss 1.8833\n","Epoch 1 Batch 300 Loss 1.7781\n","Epoch 1 Loss 2.0130\n","Time taken for 1 epoch 47.950162172317505 sec\n","\n","Epoch 2 Batch 0 Loss 1.6033\n","Epoch 2 Batch 100 Loss 1.5928\n","Epoch 2 Batch 200 Loss 1.2855\n","Epoch 2 Batch 300 Loss 1.2566\n","Epoch 2 Loss 1.3561\n","Time taken for 1 epoch 26.302316427230835 sec\n","\n","Epoch 3 Batch 0 Loss 1.0808\n","Epoch 3 Batch 100 Loss 0.9976\n","Epoch 3 Batch 200 Loss 0.9918\n","Epoch 3 Batch 300 Loss 0.8526\n","Epoch 3 Loss 0.9371\n","Time taken for 1 epoch 26.41278338432312 sec\n","\n","Epoch 4 Batch 0 Loss 0.6094\n","Epoch 4 Batch 100 Loss 0.6765\n","Epoch 4 Batch 200 Loss 0.7269\n","Epoch 4 Batch 300 Loss 0.5609\n","Epoch 4 Loss 0.6261\n","Time taken for 1 epoch 26.271003246307373 sec\n","\n","Epoch 5 Batch 0 Loss 0.4354\n","Epoch 5 Batch 100 Loss 0.4500\n","Epoch 5 Batch 200 Loss 0.4365\n","Epoch 5 Batch 300 Loss 0.3384\n","Epoch 5 Loss 0.4196\n","Time taken for 1 epoch 26.143457889556885 sec\n","\n","Epoch 6 Batch 0 Loss 0.2422\n","Epoch 6 Batch 100 Loss 0.2969\n","Epoch 6 Batch 200 Loss 0.3321\n","Epoch 6 Batch 300 Loss 0.2886\n","Epoch 6 Loss 0.2892\n","Time taken for 1 epoch 26.698626041412354 sec\n","\n","Epoch 7 Batch 0 Loss 0.1767\n","Epoch 7 Batch 100 Loss 0.2097\n","Epoch 7 Batch 200 Loss 0.2120\n","Epoch 7 Batch 300 Loss 0.2010\n","Epoch 7 Loss 0.2063\n","Time taken for 1 epoch 26.638314723968506 sec\n","\n","Epoch 8 Batch 0 Loss 0.1604\n","Epoch 8 Batch 100 Loss 0.1453\n","Epoch 8 Batch 200 Loss 0.1455\n","Epoch 8 Batch 300 Loss 0.1595\n","Epoch 8 Loss 0.1497\n","Time taken for 1 epoch 26.53403067588806 sec\n","\n","Epoch 9 Batch 0 Loss 0.1579\n","Epoch 9 Batch 100 Loss 0.1179\n","Epoch 9 Batch 200 Loss 0.1393\n","Epoch 9 Batch 300 Loss 0.1183\n","Epoch 9 Loss 0.1182\n","Time taken for 1 epoch 26.808876752853394 sec\n","\n","Epoch 10 Batch 0 Loss 0.0715\n","Epoch 10 Batch 100 Loss 0.1096\n","Epoch 10 Batch 200 Loss 0.1085\n","Epoch 10 Batch 300 Loss 0.1023\n","Epoch 10 Loss 0.0962\n","Time taken for 1 epoch 26.619587421417236 sec\n","\n"]}]},{"cell_type":"code","source":["def evaluate(sentence):\n","  attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","  sentence = preprocess_sentence(sentence)\n","\n","  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = [tf.zeros((1, units))]\n","  enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","  for t in range(max_length_targ):\n","    predictions, dec_hidden, attention_weights = decoder(dec_input,\n","                                                         dec_hidden,\n","                                                         enc_out)\n","\n","    # storing the attention weights to plot later on\n","    attention_weights = tf.reshape(attention_weights, (-1, ))\n","    attention_plot[t] = attention_weights.numpy()\n","\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","    result += targ_lang.index_word[predicted_id] + ' '\n","\n","    if targ_lang.index_word[predicted_id] == '<end>':\n","      return result, sentence, attention_plot\n","\n","    # the predicted ID is fed back into the model\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence, attention_plot"],"metadata":{"id":"Yh8d5R5LTIWW","executionInfo":{"status":"ok","timestamp":1679798528633,"user_tz":-540,"elapsed":11,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","  fig = plt.figure(figsize=(10,10))\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.matshow(attention, cmap='viridis')\n","\n","  fontdict = {'fontsize': 14}\n","\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","  plt.show()"],"metadata":{"id":"xR-NooWETJFh","executionInfo":{"status":"ok","timestamp":1679798528633,"user_tz":-540,"elapsed":11,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["def translate(sentence):\n","  result, sentence, attention_plot = evaluate(sentence)\n","\n","  print('Input: %s' % (sentence))\n","  print('Predicted translation: {}'.format(result))\n","\n","  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"],"metadata":{"id":"fo31uSG9TKYQ","executionInfo":{"status":"ok","timestamp":1679798528633,"user_tz":-540,"elapsed":10,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["translate(u'hace mucho frio aqui.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":751},"id":"UNGfWSgbTK8u","executionInfo":{"status":"ok","timestamp":1679798529234,"user_tz":-540,"elapsed":611,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"c332cc46-7efe-47f3-88df-aa1915389f62"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: <start> hace mucho frio aqui . <end>\n","Predicted translation: it s too cold here . <end> \n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-36-ef64c003f9d5>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","<ipython-input-36-ef64c003f9d5>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["translate(u'esta es mi vida.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":751},"id":"vRS4C8urTL6R","executionInfo":{"status":"ok","timestamp":1679798529817,"user_tz":-540,"elapsed":591,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"6d497dd1-bbf2-40ed-ef8c-b80439d9ad43"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: <start> esta es mi vida . <end>\n","Predicted translation: this is my life . <end> \n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-36-ef64c003f9d5>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","<ipython-input-36-ef64c003f9d5>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## Review\n","\n","- 언어 모델 (Language Model)\n","    - 통계 기반의 언어 모델(Statistical Language Model)\n","    - 신경망 언어 모델(Neural Network Language Model) \n","\n","- 순환 신경망 (Recurrent Neural Network, RNN)\n","    - RNN의 구조\n","    - RNN의 장점과 단점\n","        - 기울기 소실(Gradient Vanishing)\n","\n","- LSTM & GRU\n","    - LSTM\n","        - Cell state\n","    - GRU\n","\n","- Attention\n","    - Attention\n","        - 장기 의존성(Long-term Dependency)\n","    - Query, Key, Vector\n","        - 어떤 벡터가 각 요소에 해당될까요?"],"metadata":{"id":"JJ_k9dJTTNxK"}},{"cell_type":"markdown","source":["# Exercise\n","\n","다음 링크는 LSTM을 사용하여 Spam 메시지 분류를 수행한 캐글 노트북입니다. => [Link](https://www.kaggle.com/kredy10/simple-lstm-for-text-classification) <br/>\n","\n","위 노트북에서 사용한 코드를 참고하여<br/>\n","캐글 데이터셋인 [Women's E-Commerce Clothing Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews) 를 분류해 보세요.\n","\n","- 분류에 사용될 텍스트 데이터 : **`Review Text`** 열을 사용합니다.\n","- 레이블(label) 데이터 : **`Recommended IND`** 열을 사용합니다."],"metadata":{"id":"Wvz0_DGZTUXw"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.callbacks import EarlyStopping\n","%matplotlib inline"],"metadata":{"id":"Z3yMEUPWTMxI","executionInfo":{"status":"ok","timestamp":1679798529817,"user_tz":-540,"elapsed":11,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(action='ignore')"],"metadata":{"id":"vAxrWPzATXpT","executionInfo":{"status":"ok","timestamp":1679798529818,"user_tz":-540,"elapsed":12,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","\n","file = files.upload()\n","df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', delimiter=',',encoding='latin-1')\n","df.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"e_mcBBLuTYRK","executionInfo":{"status":"ok","timestamp":1679798683015,"user_tz":-540,"elapsed":81291,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"7819545d-9721-45dc-97a3-1a5e0eec7d3c"},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-450b829c-fc6e-4a96-a06d-78a4c0977dcf\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-450b829c-fc6e-4a96-a06d-78a4c0977dcf\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Womens Clothing E-Commerce Reviews.csv to Womens Clothing E-Commerce Reviews.csv\n"]},{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  Clothing ID  Age                    Title  \\\n","0           0          767   33                      NaN   \n","1           1         1080   34                      NaN   \n","2           2         1077   60  Some major design flaws   \n","\n","                                         Review Text  Rating  Recommended IND  \\\n","0  Absolutely wonderful - silky and sexy and comf...       4                1   \n","1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n","2  I had such high hopes for this dress and reall...       3                0   \n","\n","   Positive Feedback Count Division Name Department Name Class Name  \n","0                        0     Initmates        Intimate  Intimates  \n","1                        4       General         Dresses    Dresses  \n","2                        0       General         Dresses    Dresses  "],"text/html":["\n","  <div id=\"df-8b322de7-33e7-4785-a3f5-d3c2a2614bae\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Clothing ID</th>\n","      <th>Age</th>\n","      <th>Title</th>\n","      <th>Review Text</th>\n","      <th>Rating</th>\n","      <th>Recommended IND</th>\n","      <th>Positive Feedback Count</th>\n","      <th>Division Name</th>\n","      <th>Department Name</th>\n","      <th>Class Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>767</td>\n","      <td>33</td>\n","      <td>NaN</td>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Initmates</td>\n","      <td>Intimate</td>\n","      <td>Intimates</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1080</td>\n","      <td>34</td>\n","      <td>NaN</td>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1077</td>\n","      <td>60</td>\n","      <td>Some major design flaws</td>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>General</td>\n","      <td>Dresses</td>\n","      <td>Dresses</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b322de7-33e7-4785-a3f5-d3c2a2614bae')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8b322de7-33e7-4785-a3f5-d3c2a2614bae button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8b322de7-33e7-4785-a3f5-d3c2a2614bae');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","source":["### 1) 데이터 전처리\n","    \n","- 데이터셋을 데이터프레임으로 읽어옵니다.\n","- 필요없는 열(column)을 삭제합니다."],"metadata":{"id":"HGoPoWuGTZj2"}},{"cell_type":"code","source":["np.random.seed(42)\n","tf.random.set_seed(42)"],"metadata":{"id":"LWJWw1S1TY0_","executionInfo":{"status":"ok","timestamp":1679798686571,"user_tz":-540,"elapsed":269,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["df = df[['Review Text', 'Recommended IND']]"],"metadata":{"id":"PxjwEtVwTaVn","executionInfo":{"status":"ok","timestamp":1679798686572,"user_tz":-540,"elapsed":8,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"lgRMQEHdTbfB","executionInfo":{"status":"ok","timestamp":1679798686572,"user_tz":-540,"elapsed":8,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"762e7624-d156-4b8b-cb8a-909847d7056c"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             Review Text  Recommended IND\n","0      Absolutely wonderful - silky and sexy and comf...                1\n","1      Love this dress!  it's sooo pretty.  i happene...                1\n","2      I had such high hopes for this dress and reall...                0\n","3      I love, love, love this jumpsuit. it's fun, fl...                1\n","4      This shirt is very flattering to all due to th...                1\n","...                                                  ...              ...\n","23481  I was very happy to snag this dress at such a ...                1\n","23482  It reminds me of maternity clothes. soft, stre...                1\n","23483  This fit well, but the top was very see throug...                0\n","23484  I bought this dress for a wedding i have this ...                1\n","23485  This dress in a lovely platinum is feminine an...                1\n","\n","[23486 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-65cb496b-43ea-4058-82b5-957e25c2d039\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review Text</th>\n","      <th>Recommended IND</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Absolutely wonderful - silky and sexy and comf...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I had such high hopes for this dress and reall...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This shirt is very flattering to all due to th...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>23481</th>\n","      <td>I was very happy to snag this dress at such a ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23482</th>\n","      <td>It reminds me of maternity clothes. soft, stre...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23483</th>\n","      <td>This fit well, but the top was very see throug...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23484</th>\n","      <td>I bought this dress for a wedding i have this ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23485</th>\n","      <td>This dress in a lovely platinum is feminine an...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23486 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65cb496b-43ea-4058-82b5-957e25c2d039')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-65cb496b-43ea-4058-82b5-957e25c2d039 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-65cb496b-43ea-4058-82b5-957e25c2d039');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["sns.countplot(df['Recommended IND']);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"H3s0wGCeTcOU","executionInfo":{"status":"ok","timestamp":1679798687138,"user_tz":-540,"elapsed":573,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"cd3920b4-322e-41cb-989d-1d720d6ad3b3"},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5QdI6PXTdAB","executionInfo":{"status":"ok","timestamp":1679798687139,"user_tz":-540,"elapsed":10,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"62010c02-4286-4684-e2c1-1ad484e5737f"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Review Text        845\n","Recommended IND      0\n","dtype: int64"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["df.dropna(inplace=True)"],"metadata":{"id":"XFWVxfHxTdu8","executionInfo":{"status":"ok","timestamp":1679798687522,"user_tz":-540,"elapsed":2,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["X = df['Review Text']\n","y = df['Recommended IND']\n","\n","y = np.array(y)\n","y = y.reshape(-1, 1)"],"metadata":{"id":"IHV2HHZ1TeQw","executionInfo":{"status":"ok","timestamp":1679798687523,"user_tz":-540,"elapsed":3,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["### 2) 텍스트 분류를 수행해주세요.\n","\n","- 데이터셋 split시 test_size의 비율은 20%로, `random_state = 42` 로 설정합니다. \n","- Tokenizer의 `num_words=3000` 으로 설정합니다.\n","- pad_sequence의 `maxlen=400` 으로 설정합니다.\n","- 학습 시, 파라미터는 `batch_size=128, epochs=10, validation_split=0.2` 로 설정합니다.\n","- EarlyStopping을 적용합니다. 파라미터는 `monitor='val_loss',min_delta=0.0001, patience=3` 로 설정합니다.\n","- evaluate 했을 때의 loss와 accuarcy를 [loss, acc] 형태로 입력해주세요. Ex) [0.4321, 0.8765]"],"metadata":{"id":"Bg0PNQv4TfcJ"}},{"cell_type":"code","source":["X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state = 42)"],"metadata":{"id":"_CFL_PO9Tevh","executionInfo":{"status":"ok","timestamp":1679798687523,"user_tz":-540,"elapsed":2,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["num_words = 3000\n","max_len = 400\n","tok = Tokenizer(num_words=num_words)\n","tok.fit_on_texts(X_train)\n","sequences = tok.texts_to_sequences(X_train)\n","sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"],"metadata":{"id":"S5WaGIz0TgnH","executionInfo":{"status":"ok","timestamp":1679798688699,"user_tz":-540,"elapsed":1178,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["def RNN():\n","    inputs = Input(name='inputs',shape=[max_len])\n","    layer = Embedding(num_words,50,input_length=max_len)(inputs)\n","    layer = LSTM(64)(layer)\n","    layer = Dense(256,name='FC1')(layer)\n","    layer = Activation('relu')(layer)\n","    layer = Dropout(0.5)(layer)\n","    layer = Dense(1,name='out_layer')(layer)\n","    layer = Activation('sigmoid')(layer)\n","    model = Model(inputs=inputs,outputs=layer)\n","    return model"],"metadata":{"id":"RQRGzI_hThIa","executionInfo":{"status":"ok","timestamp":1679798688700,"user_tz":-540,"elapsed":3,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["model = RNN()\n","model.summary()\n","model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3QqidxxThlz","executionInfo":{"status":"ok","timestamp":1679798689213,"user_tz":-540,"elapsed":515,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"182df700-55dd-4251-ca82-b4aecf0a20e9"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," inputs (InputLayer)         [(None, 400)]             0         \n","                                                                 \n"," embedding_3 (Embedding)     (None, 400, 50)           150000    \n","                                                                 \n"," lstm_2 (LSTM)               (None, 64)                29440     \n","                                                                 \n"," FC1 (Dense)                 (None, 256)               16640     \n","                                                                 \n"," activation (Activation)     (None, 256)               0         \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," out_layer (Dense)           (None, 1)                 257       \n","                                                                 \n"," activation_1 (Activation)   (None, 1)                 0         \n","                                                                 \n","=================================================================\n","Total params: 196,337\n","Trainable params: 196,337\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.fit(sequences_matrix, y_train, batch_size=128, epochs=10,\n","          validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001, patience=3)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJa3Cpw9TiX4","executionInfo":{"status":"ok","timestamp":1679798732495,"user_tz":-540,"elapsed":43295,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"aa07e643-16ee-4e50-8d48-b8b68a2b9cc1"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","114/114 [==============================] - 17s 126ms/step - loss: 0.4280 - accuracy: 0.8299 - val_loss: 0.3115 - val_accuracy: 0.8625\n","Epoch 2/10\n","114/114 [==============================] - 7s 64ms/step - loss: 0.2723 - accuracy: 0.8843 - val_loss: 0.3349 - val_accuracy: 0.8380\n","Epoch 3/10\n","114/114 [==============================] - 5s 47ms/step - loss: 0.2344 - accuracy: 0.9001 - val_loss: 0.3052 - val_accuracy: 0.8490\n","Epoch 4/10\n","114/114 [==============================] - 4s 37ms/step - loss: 0.2145 - accuracy: 0.9122 - val_loss: 0.2804 - val_accuracy: 0.8774\n","Epoch 5/10\n","114/114 [==============================] - 3s 24ms/step - loss: 0.1983 - accuracy: 0.9188 - val_loss: 0.3406 - val_accuracy: 0.8860\n","Epoch 6/10\n","114/114 [==============================] - 3s 29ms/step - loss: 0.1889 - accuracy: 0.9246 - val_loss: 0.2993 - val_accuracy: 0.8786\n","Epoch 7/10\n","114/114 [==============================] - 3s 29ms/step - loss: 0.1802 - accuracy: 0.9282 - val_loss: 0.3133 - val_accuracy: 0.8816\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1c53ddae80>"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["test_sequences = tok.texts_to_sequences(X_test)\n","test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"],"metadata":{"id":"jv4zc9XGTjLO","executionInfo":{"status":"ok","timestamp":1679798773086,"user_tz":-540,"elapsed":40601,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["accr = model.evaluate(test_sequences_matrix, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5-UIwGLTjwc","executionInfo":{"status":"ok","timestamp":1679798774325,"user_tz":-540,"elapsed":1254,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"5f7fb1ad-833b-4b2a-82a9-348169b28b4e"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["142/142 [==============================] - 1s 8ms/step - loss: 0.2806 - accuracy: 0.8867\n"]}]},{"cell_type":"code","source":["print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vVrBDf6iTkRf","executionInfo":{"status":"ok","timestamp":1679798774325,"user_tz":-540,"elapsed":6,"user":{"displayName":"박지수","userId":"15151265950850399854"}},"outputId":"5021b33d-4c0e-4a34-f47d-59845c590648"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Test set\n","  Loss: 0.281\n","  Accuracy: 0.887\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZPgRm3_kTlCT","executionInfo":{"status":"ok","timestamp":1679798774326,"user_tz":-540,"elapsed":5,"user":{"displayName":"박지수","userId":"15151265950850399854"}}},"execution_count":58,"outputs":[]}]}